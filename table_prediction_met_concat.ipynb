{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Students_Grading_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually select Cols (attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>52.29</td>\n",
       "      <td>55.03</td>\n",
       "      <td>57.82</td>\n",
       "      <td>84.22</td>\n",
       "      <td>74.06</td>\n",
       "      <td>85.90</td>\n",
       "      <td>56.09</td>\n",
       "      <td>F</td>\n",
       "      <td>6.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.23</td>\n",
       "      <td>45.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.24</td>\n",
       "      <td>55.65</td>\n",
       "      <td>50.64</td>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Business</td>\n",
       "      <td>57.19</td>\n",
       "      <td>67.05</td>\n",
       "      <td>93.68</td>\n",
       "      <td>67.70</td>\n",
       "      <td>85.70</td>\n",
       "      <td>73.79</td>\n",
       "      <td>70.30</td>\n",
       "      <td>D</td>\n",
       "      <td>20.7</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>95.15</td>\n",
       "      <td>47.79</td>\n",
       "      <td>80.63</td>\n",
       "      <td>66.06</td>\n",
       "      <td>93.51</td>\n",
       "      <td>92.12</td>\n",
       "      <td>61.63</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>54.18</td>\n",
       "      <td>46.59</td>\n",
       "      <td>78.89</td>\n",
       "      <td>96.85</td>\n",
       "      <td>83.70</td>\n",
       "      <td>68.42</td>\n",
       "      <td>66.13</td>\n",
       "      <td>F</td>\n",
       "      <td>15.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.15</td>\n",
       "      <td>60.33</td>\n",
       "      <td>80.09</td>\n",
       "      <td>99.32</td>\n",
       "      <td>58.42</td>\n",
       "      <td>85.21</td>\n",
       "      <td>D</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Low</td>\n",
       "      <td>10</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>65.11</td>\n",
       "      <td>86.31</td>\n",
       "      <td>49.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.08</td>\n",
       "      <td>60.87</td>\n",
       "      <td>95.96</td>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>CS</td>\n",
       "      <td>87.54</td>\n",
       "      <td>63.55</td>\n",
       "      <td>64.21</td>\n",
       "      <td>94.28</td>\n",
       "      <td>50.19</td>\n",
       "      <td>82.65</td>\n",
       "      <td>54.25</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>92.56</td>\n",
       "      <td>79.79</td>\n",
       "      <td>94.28</td>\n",
       "      <td>81.20</td>\n",
       "      <td>61.18</td>\n",
       "      <td>94.29</td>\n",
       "      <td>55.84</td>\n",
       "      <td>A</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>83.92</td>\n",
       "      <td>83.24</td>\n",
       "      <td>53.47</td>\n",
       "      <td>51.76</td>\n",
       "      <td>83.51</td>\n",
       "      <td>69.25</td>\n",
       "      <td>77.86</td>\n",
       "      <td>F</td>\n",
       "      <td>29.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age   Department  Attendance (%)  Midterm_Score  Final_Score  \\\n",
       "0     Female   22  Engineering           52.29          55.03        57.82   \n",
       "1       Male   18  Engineering           97.27          97.23        45.80   \n",
       "2       Male   24     Business           57.19          67.05        93.68   \n",
       "3     Female   24  Mathematics           95.15          47.79        80.63   \n",
       "4     Female   23           CS           54.18          46.59        78.89   \n",
       "...      ...  ...          ...             ...            ...          ...   \n",
       "4995    Male   19     Business             NaN          82.15        60.33   \n",
       "4996    Male   19     Business           65.11          86.31        49.80   \n",
       "4997  Female   24           CS           87.54          63.55        64.21   \n",
       "4998    Male   23           CS           92.56          79.79        94.28   \n",
       "4999  Female   21  Engineering           83.92          83.24        53.47   \n",
       "\n",
       "      Assignments_Avg  Quizzes_Avg  Projects_Score  Total_Score Grade  \\\n",
       "0               84.22        74.06           85.90        56.09     F   \n",
       "1                 NaN        94.24           55.65        50.64     A   \n",
       "2               67.70        85.70           73.79        70.30     D   \n",
       "3               66.06        93.51           92.12        61.63     A   \n",
       "4               96.85        83.70           68.42        66.13     F   \n",
       "...               ...          ...             ...          ...   ...   \n",
       "4995            80.09        99.32           58.42        85.21     D   \n",
       "4996              NaN        88.08           60.87        95.96     C   \n",
       "4997            94.28        50.19           82.65        54.25     A   \n",
       "4998            81.20        61.18           94.29        55.84     A   \n",
       "4999            51.76        83.51           69.25        77.86     F   \n",
       "\n",
       "      Study_Hours_per_Week Extracurricular_Activities Internet_Access_at_Home  \\\n",
       "0                      6.2                         No                     Yes   \n",
       "1                     19.0                         No                     Yes   \n",
       "2                     20.7                         No                     Yes   \n",
       "3                     24.8                        Yes                     Yes   \n",
       "4                     15.4                        Yes                     Yes   \n",
       "...                    ...                        ...                     ...   \n",
       "4995                  25.5                         No                     Yes   \n",
       "4996                   5.0                         No                     Yes   \n",
       "4997                  24.8                        Yes                      No   \n",
       "4998                  16.1                        Yes                     Yes   \n",
       "4999                  29.2                         No                     Yes   \n",
       "\n",
       "     Parent_Education_Level Family_Income_Level  Stress_Level (1-10)  \\\n",
       "0               High School              Medium                    5   \n",
       "1                       NaN              Medium                    4   \n",
       "2                  Master's                 Low                    6   \n",
       "3               High School                High                    3   \n",
       "4               High School                High                    2   \n",
       "...                     ...                 ...                  ...   \n",
       "4995            High School                 Low                   10   \n",
       "4996                    NaN              Medium                    4   \n",
       "4997            High School              Medium                    4   \n",
       "4998             Bachelor's                 Low                    1   \n",
       "4999                    PhD                 Low                    2   \n",
       "\n",
       "      Sleep_Hours_per_Night  \n",
       "0                       4.7  \n",
       "1                       9.0  \n",
       "2                       6.2  \n",
       "3                       6.7  \n",
       "4                       7.1  \n",
       "...                     ...  \n",
       "4995                    8.3  \n",
       "4996                    4.0  \n",
       "4997                    6.3  \n",
       "4998                    8.4  \n",
       "4999                    6.1  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unimportant_attribute = ['Student_ID', 'First_Name', 'Last_Name', 'Email', 'Participation_Score']\n",
    "\n",
    "filtered_df = df.drop(unimportant_attribute, axis=1)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sleep_Hours_per_Night', 'Stress_Level (1-10)', 'Study_Hours_per_Week', 'Age']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "# numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score', 'Stress_Level (1-10)']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate rows with-Nan and without-Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row with Nan: (2419, 18)\n",
      "row without Nan: (2581, 18)\n"
     ]
    }
   ],
   "source": [
    "nan_rows = filtered_df.isna().any(axis=1)\n",
    "\n",
    "# Nan rows\n",
    "df_nan = filtered_df[nan_rows]\n",
    "print(f\"row with Nan: {df_nan.shape}\")\n",
    "\n",
    "# Complete rows\n",
    "df_complete = filtered_df[~nan_rows]\n",
    "print(f\"row without Nan: {df_complete.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: (1806, 18)\n",
      "df_valid: (775, 18)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid, _, _ = train_test_split(df_complete, df_complete, test_size=0.3, random_state=0)\n",
    "\n",
    "df_train_id = [i for i in range(len(df_train))]\n",
    "df_valid_id = [i for i in range(len(df_valid))]\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_valid: {df_valid.shape}\")\n",
    "\n",
    "# print(f\"df_train_id: {df_train_id}\")\n",
    "# print(f\"df_valid_id: {df_valid_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: \n",
    "1. category to numerical\n",
    "2. max-min norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_to_numerical(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data)\n",
    "    num_data = le.transform(data)\n",
    "    \n",
    "    return num_data, le\n",
    "\n",
    "def max_min_norm_score(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "    \n",
    "def max_min_norm_scalar(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "\n",
    "    \n",
    "def preprocessing(df, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        train_params = {}\n",
    "        category_var_len = {}\n",
    "\n",
    "    # Category \n",
    "    for cat_name in category_vars:\n",
    "        cat_var = df[cat_name]\n",
    "        if process_type == 'train':\n",
    "            cat_var, le = category_to_numerical(cat_var)\n",
    "            train_params[f'{cat_name}_le'] = le\n",
    "            category_var_len[f'{cat_name}'] = len(np.unique(cat_var))\n",
    "        else:\n",
    "            cat_var = train_params[f'{cat_name}_le'].transform(cat_var)\n",
    "        new_df[f'{cat_name}'] = cat_var\n",
    "    \n",
    "    # Numerical score\n",
    "    for num_name in numerical_score_vars:\n",
    "        num_var = df[num_name]\n",
    "        if process_type == 'train':\n",
    "            num_var, data_max, data_min = max_min_norm_score(num_var, process_type = 'train')\n",
    "            train_params[num_name] = [data_max, data_min]\n",
    "        else:\n",
    "            num_var = max_min_norm_score(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "    \n",
    "    # Numerical scalar\n",
    "    for num_name in numerical_scalar_vars:\n",
    "        num_var = df[num_name]\n",
    "        num_var = np.log(num_var)\n",
    "        if process_type == 'train':\n",
    "            num_var, data_max, data_min = max_min_norm_scalar(num_var, process_type = 'train')\n",
    "            train_params[num_name] = [data_max, data_min]\n",
    "        else:\n",
    "            num_var = max_min_norm_scalar(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "        \n",
    "        \n",
    "    if process_type == 'train':\n",
    "        return new_df, train_params, category_var_len\n",
    "    else:\n",
    "        return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_var_len: {'Gender': 2, 'Department': 4, 'Grade': 5, 'Extracurricular_Activities': 2, 'Internet_Access_at_Home': 2, 'Parent_Education_Level': 4, 'Family_Income_Level': 3}\n",
      "processed_df_train: (1806, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.212823</td>\n",
       "      <td>0.138629</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>0.317805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.193152</td>\n",
       "      <td>0.069315</td>\n",
       "      <td>0.177495</td>\n",
       "      <td>0.313549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>0.158924</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.293916</td>\n",
       "      <td>0.294444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.210413</td>\n",
       "      <td>0.230259</td>\n",
       "      <td>0.282138</td>\n",
       "      <td>0.294444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.5204</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.179176</td>\n",
       "      <td>0.184055</td>\n",
       "      <td>0.304452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           1      1                           1   \n",
       "1       1           3      2                           0   \n",
       "2       1           1      4                           0   \n",
       "3       1           2      2                           1   \n",
       "4       0           2      1                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       0                    1   \n",
       "1                        1                       3                    2   \n",
       "2                        1                       1                    1   \n",
       "3                        1                       1                    2   \n",
       "4                        1                       1                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0          0.8989         0.4255       0.5045           0.5528       0.7634   \n",
       "1          0.5562         0.8190       0.4543           0.5380       0.9215   \n",
       "2          0.6309         0.6057       0.5680           0.5342       0.8288   \n",
       "3          0.6077         0.9869       0.4550           0.5771       0.5339   \n",
       "4          0.9590         0.8459       0.6858           0.5204       0.6389   \n",
       "\n",
       "   Projects_Score  Total_Score  Sleep_Hours_per_Night  Stress_Level (1-10)  \\\n",
       "0          0.5783       0.7426               0.212823             0.138629   \n",
       "1          0.6371       0.8995               0.193152             0.069315   \n",
       "2          0.5671       0.5943               0.158924             0.194591   \n",
       "3          0.5516       0.8337               0.210413             0.230259   \n",
       "4          0.6554       0.8854               0.218605             0.179176   \n",
       "\n",
       "   Study_Hours_per_Week       Age  \n",
       "0              0.332504  0.317805  \n",
       "1              0.177495  0.313549  \n",
       "2              0.293916  0.294444  \n",
       "3              0.282138  0.294444  \n",
       "4              0.184055  0.304452  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_train, train_params, category_var_len = preprocessing(df_train, process_type = 'train')\n",
    "# train_params\n",
    "print(f\"category_var_len: {category_var_len}\")\n",
    "print(f\"processed_df_train: {processed_df_train.shape}\")\n",
    "\n",
    "cols_name = processed_df_train.columns\n",
    "processed_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_df_valid: (775, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.214007</td>\n",
       "      <td>0.207944</td>\n",
       "      <td>0.283908</td>\n",
       "      <td>0.294444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.141099</td>\n",
       "      <td>0.207944</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.289037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.193152</td>\n",
       "      <td>0.219722</td>\n",
       "      <td>0.294969</td>\n",
       "      <td>0.317805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.185630</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.319458</td>\n",
       "      <td>0.304452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.200148</td>\n",
       "      <td>0.109861</td>\n",
       "      <td>0.236085</td>\n",
       "      <td>0.313549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           3      2                           0   \n",
       "1       1           1      1                           1   \n",
       "2       1           3      2                           0   \n",
       "3       1           1      3                           1   \n",
       "4       1           2      0                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       2                    1   \n",
       "1                        1                       2                    1   \n",
       "2                        1                       3                    0   \n",
       "3                        1                       2                    1   \n",
       "4                        1                       0                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0          0.5154         0.6404       0.5002           0.8728       0.9699   \n",
       "1          0.9970         0.9376       0.6142           0.5457       0.7576   \n",
       "2          0.6151         0.7315       0.4190           0.5537       0.5564   \n",
       "3          0.5228         0.8212       0.9962           0.5518       0.5023   \n",
       "4          0.9474         0.5340       0.6216           0.8329       0.7903   \n",
       "\n",
       "   Projects_Score  Total_Score  Sleep_Hours_per_Night  Stress_Level (1-10)  \\\n",
       "0          0.8258       0.8888               0.214007             0.207944   \n",
       "1          0.5397       0.6468               0.141099             0.207944   \n",
       "2          0.7862       0.5429               0.193152             0.219722   \n",
       "3          0.8334       0.6564               0.185630             0.194591   \n",
       "4          0.6250       0.6557               0.200148             0.109861   \n",
       "\n",
       "   Study_Hours_per_Week       Age  \n",
       "0              0.283908  0.294444  \n",
       "1              0.194591  0.289037  \n",
       "2              0.294969  0.317805  \n",
       "3              0.319458  0.304452  \n",
       "4              0.236085  0.313549  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_valid = preprocessing(df_valid, train_params, process_type = 'valid')\n",
    "print(f\"processed_df_valid: {processed_df_valid.shape}\")\n",
    "processed_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "MASK_RATIO = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_helper(data, MASK_RATIO, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    rows, cols = data.shape\n",
    "    \n",
    "    # define mask/unmask ratio\n",
    "    unmask_ratio = ((100 - MASK_RATIO) * cols) // 100\n",
    "    mask_ratio = cols - unmask_ratio\n",
    "\n",
    "    # create random index\n",
    "    # shuff_idx = np.array([np.random.permutation(cols) for _ in range(rows)])\n",
    "    shuff_idx = np.random.permutation(cols).reshape(1, cols)\n",
    "    shuff_idx = np.repeat(shuff_idx, rows, axis = 0)\n",
    "\n",
    "    # define mask/unmask idx\n",
    "    mask_idx = shuff_idx[:, :mask_ratio]\n",
    "    unmask_idx = shuff_idx[:, mask_ratio:]\n",
    "    \n",
    "    mask_idx.sort(axis=1)\n",
    "    unmask_idx.sort(axis=1)\n",
    "    \n",
    "    # create new_data (contain unmask cols, but remove mask cols)\n",
    "    new_data = np.zeros((rows, unmask_ratio))\n",
    "    for i in range(rows):\n",
    "        new_data[i] = data[i][unmask_idx[i]]\n",
    "        \n",
    "    return new_data, unmask_idx, mask_idx, unmask_ratio\n",
    "\n",
    "def masking_fn(data, seed):\n",
    "    sample_size = len(data)\n",
    "\n",
    "    new_data, unmask_idx, mask_idx, unmask_ratio = masking_helper(data, MASK_RATIO, seed)\n",
    "        \n",
    "    X = [[],[],[],[]]\n",
    "    Y = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        X[0].append(new_data[i]) # unmask data\n",
    "        X[1].append(unmask_idx[i]) # unmask id\n",
    "        X[2].append(mask_idx[i]) # mask id\n",
    "        X[3].append(np.ones(unmask_ratio)) # len = unmask, serve as random noisee in VAE\n",
    "        Y.append(data[i][list(unmask_idx[i])+list(mask_idx[i])]) # label (unmask + mask)\n",
    "\n",
    "    X[0] = torch.tensor(np.array(X[0])) # unmask data\n",
    "    X[1] = torch.tensor(np.array(X[1])) # unmask id\n",
    "    X[2] = torch.tensor(np.array(X[2])) # mask id\n",
    "    X[3] = torch.tensor(np.array(X[3])) # latent space\n",
    "    \n",
    "    Y = torch.tensor(np.array(Y))\n",
    "    \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(data_wtih_type):\n",
    "\n",
    "    # data\n",
    "    data = [dat[0] for dat in data_wtih_type]\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # data type: training/valid\n",
    "    data_type = data_wtih_type[0][1]\n",
    "\n",
    "    if data_type == 'training':\n",
    "        seed = np.random.randint(3, size=1)\n",
    "    else:\n",
    "        seed = 42\n",
    "        \n",
    "    data, label = masking_fn(data, seed)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(self, data, data_type = 'training'):\n",
    "        self.data = data\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        dat = self.data.iloc[id, :]\n",
    "        dat = np.array(dat)\n",
    "        return dat, self.data_type\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "augmented_processed_df_train = pd.concat([processed_df_train, processed_df_train], axis = 0)\n",
    "train_dataset = TableDataset(augmented_processed_df_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers = 4, shuffle=False, collate_fn = collate_fn_train)\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn = collate_fn_train)\n",
    "\n",
    "\n",
    "valid_dataset = TableDataset(processed_df_valid, data_type = 'valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers = 4, shuffle=False, collate_fn = collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, num_head, encoder_emb_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.num_head = num_head\n",
    "        self.encoder_emb_dim = encoder_emb_dim\n",
    "\n",
    "        # up_emb_size * 3 for qkv\n",
    "        self.qkv_fn = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim * 3, bias=False)\n",
    "        self.proj_qkv = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim, bias = False)\n",
    "                \n",
    "        # other\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size, num_vars, _ = x.shape\n",
    "\n",
    "        # qkv: up_emb_size * 3\n",
    "        x = self.qkv_fn(x) \n",
    "        q, k, v = x.split(self.encoder_emb_dim, dim = 2) \n",
    "        \n",
    "        # split head: each shape = [batch_size, num_head, num_vars(seq_len), head_size = 8]\n",
    "        q = q.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        k = k.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        v = v.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        \n",
    "        # attention matrix calculation: [batch_size, num_head, num_vars(seq_len), num_vars]\n",
    "        att = (q @ k.transpose(-2,-1)) * (1 / torch.sqrt(torch.ones([1]).to(device) * k.size(-1)))\n",
    "        att = F.softmax(att, dim = -1)\n",
    "        att = self.att_dropout(att)\n",
    "        \n",
    "        # att matrix * V: [batch_size, num_head, num_vars(seq_len), head_size]\n",
    "        out = att @ v\n",
    "        out = out.transpose(1,2).contiguous().view(batch_size, num_vars, self.encoder_emb_dim)\n",
    "        out = self.proj_qkv(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, transformer_emb_size, dropout):\n",
    "        super().__init__()\n",
    "        self.up    = nn.Linear(transformer_emb_size, transformer_emb_size * 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.down  = nn.Linear(transformer_emb_size * 3, transformer_emb_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.down(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, num_head, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        self.ln_head = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.head = Head(num_head, encoder_emb_dim, dropout)\n",
    "        self.dropout_head = nn.Dropout(dropout)\n",
    "\n",
    "        self.ln_mlp = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.mlp = MLP(encoder_emb_dim, dropout)\n",
    "        self.dropout_mlp = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # att \n",
    "        ori_x = x \n",
    "        x = self.head(x)\n",
    "        x = self.dropout_head(x)\n",
    "        x = self.ln_head(ori_x + x)\n",
    "        \n",
    "        # linear \n",
    "        ori_x = x \n",
    "        x = self.mlp(x)\n",
    "        x = self.dropout_mlp(x)\n",
    "        x = self.ln_mlp(ori_x + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(Block(encoder_emb_dim, num_head, dropout) for _ in range(layers))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sleep_Hours_per_Night', 'Stress_Level (1-10)', 'Study_Hours_per_Week', 'Age']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Embed(nn.Module):\n",
    "    def __init__(self, cols_name, category_vars, feature_emb_size, num_variables, position_emb_dim, category_var_len):\n",
    "        super().__init__()\n",
    "        self.cols_name = cols_name\n",
    "        self.category_vars = category_vars\n",
    "        self.feature_emb_size = feature_emb_size\n",
    "        self.category_var_len = category_var_len\n",
    "        self.hidden_size = feature_emb_size + position_emb_dim\n",
    "\n",
    "        # Category feature embedding\n",
    "        self.cat_encoders = {\n",
    "            'Gender': nn.Embedding(category_var_len['Gender'] + 1, feature_emb_size),\n",
    "            'Department': nn.Embedding(category_var_len['Department'] + 1, feature_emb_size),\n",
    "            'Grade': nn.Embedding(category_var_len['Grade'] + 1, feature_emb_size),\n",
    "            'Extracurricular_Activities': nn.Embedding(category_var_len['Extracurricular_Activities'] + 1, feature_emb_size),\n",
    "            'Internet_Access_at_Home': nn.Embedding(category_var_len['Internet_Access_at_Home'] + 1, feature_emb_size),\n",
    "            'Parent_Education_Level': nn.Embedding(category_var_len['Parent_Education_Level'] + 1, feature_emb_size),\n",
    "            'Family_Income_Level': nn.Embedding(category_var_len['Family_Income_Level'] + 1, feature_emb_size),\n",
    "        }\n",
    "        \n",
    "        self.cat_decoders = {\n",
    "            'Gender': nn.Linear(self.hidden_size, category_var_len['Gender'] + 1, bias=False),\n",
    "            'Department': nn.Linear(self.hidden_size, category_var_len['Department'] + 1, bias=False),\n",
    "            'Grade': nn.Linear(self.hidden_size, category_var_len['Grade'] + 1, bias=False),\n",
    "            'Extracurricular_Activities': nn.Linear(self.hidden_size, category_var_len['Extracurricular_Activities'] + 1, bias=False),\n",
    "            'Internet_Access_at_Home': nn.Linear(self.hidden_size, category_var_len['Internet_Access_at_Home'] + 1, bias=False),\n",
    "            'Parent_Education_Level': nn.Linear(self.hidden_size, category_var_len['Parent_Education_Level'] + 1, bias=False),\n",
    "            'Family_Income_Level': nn.Linear(self.hidden_size, category_var_len['Family_Income_Level'] + 1, bias=False),\n",
    "        }\n",
    "        \n",
    "        # self.cat_encoders['Gender'].weight = self.cat_decoders['Gender'].weight        \n",
    "        # self.cat_encoders['Department'].weight = self.cat_decoders['Department'].weight        \n",
    "        # self.cat_encoders['Grade'].weight = self.cat_decoders['Grade'].weight        \n",
    "        # self.cat_encoders['Extracurricular_Activities'].weight = self.cat_decoders['Extracurricular_Activities'].weight        \n",
    "        # self.cat_encoders['Internet_Access_at_Home'].weight = self.cat_decoders['Internet_Access_at_Home'].weight        \n",
    "        # self.cat_encoders['Parent_Education_Level'].weight = self.cat_decoders['Parent_Education_Level'].weight        \n",
    "        # self.cat_encoders['Family_Income_Level'].weight = self.cat_decoders['Family_Income_Level'].weight        \n",
    "\n",
    "        # numerical decoder\n",
    "        self.numerical_decoder1 = nn.Linear(self.hidden_size, self.hidden_size * 2, bias = False)\n",
    "        self.numerical_decoder2 = nn.Linear(self.hidden_size * 2, self.hidden_size * 4, bias = False)\n",
    "        self.numerical_decoder3 = nn.Linear(self.hidden_size * 4, self.hidden_size * 2, bias = False)\n",
    "        self.numerical_decoder4 = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = False)\n",
    "        self.numerical_decoder5 = nn.Linear(self.hidden_size, 1, bias = False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.cols_id_name = {}\n",
    "        count = 0\n",
    "        for col in self.cols_name:\n",
    "            self.cols_id_name[count] = col\n",
    "            count += 1\n",
    "            \n",
    "        # positional embedding \n",
    "        self.position_emb_dim = position_emb_dim\n",
    "        self.pos_emb = nn.Embedding(num_variables, position_emb_dim)            \n",
    "\n",
    "    def encode(self, unmasked_data, unmasked_idx, masked_idx):\n",
    "        \n",
    "        batch_size, num_unmask_cols = unmasked_data.shape\n",
    "        _, num_mask_cols = masked_idx.shape\n",
    "        device = unmasked_data.device\n",
    "        \n",
    "        # position info\n",
    "        unmasked_pos_info = self.pos_emb(unmasked_idx.long()).float()\n",
    "        masked_pos_info = self.pos_emb(masked_idx.long()).float()\n",
    "\n",
    "        ''' Feature Encoding for Unmask '''\n",
    "        \n",
    "        # iterate every col in unmask\n",
    "        # for category, do nn.Embedding\n",
    "        # for numerical, repeat twice\n",
    "        unmasked_emb = []\n",
    "        for c in range(num_unmask_cols):\n",
    "            unmask_attribute_value = unmasked_data[:, c]\n",
    "            \n",
    "            # make sure unmask_attribute_id is unique along one col dimension\n",
    "            # use the unique id to see the choosen attribute is categorial or numerical\n",
    "            unmask_attribute_id = unmasked_idx[:, c]\n",
    "            assert len(torch.unique(unmask_attribute_id)) == 1, \"unmask_attribute_id in one small batch has to be the same\"\n",
    "            unmask_attribute_id = torch.unique(unmask_attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[unmask_attribute_id] in self.category_vars:\n",
    "                # print(f\"col_name: {self.cols_id_name[unmask_attribute_id]}\")\n",
    "                encoder = self.cat_encoders[self.cols_id_name[unmask_attribute_id]].to(device)\n",
    "                unmask_attribute_emb = encoder(unmask_attribute_value.long()).float()\n",
    "                unmasked_emb.append(unmask_attribute_emb)\n",
    "            # this col is numerical\n",
    "            else:\n",
    "                unmask_attribute_value = torch.unsqueeze(unmask_attribute_value, dim = 1)\n",
    "                unmask_attribute_emb = unmask_attribute_value.repeat(1, self.feature_emb_size)\n",
    "                unmasked_emb.append(unmask_attribute_emb)\n",
    "\n",
    "        unmasked_emb = torch.stack(unmasked_emb, dim = 1)\n",
    "        \n",
    "        ''' Positional Encoding for Unmask '''\n",
    "        unmasked_emb = torch.cat([unmasked_emb, unmasked_pos_info], dim = 2) # (batch_size, num_unmask_vars, feature_emb_size + pos_emb_size)\n",
    "\n",
    "        \n",
    "        ''' Feature Encoding for Mask '''\n",
    "        # create noise for categorial and numerical seperately\n",
    "        masked_emb = []\n",
    "        for c in range(num_mask_cols):\n",
    "            mask_attribute_id = masked_idx[:, c]\n",
    "            assert len(torch.unique(mask_attribute_id)) == 1, \"mask_attribute_id in one small batch has to be the same\"\n",
    "            mask_attribute_id = torch.unique(mask_attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[mask_attribute_id] in self.category_vars:\n",
    "                # get col name\n",
    "                col_name = self.cols_id_name[mask_attribute_id]\n",
    "                encoder = self.cat_encoders[col_name].to(device)\n",
    "                \n",
    "                # create categorial mask id\n",
    "                category_mask_id = self.category_var_len[col_name]\n",
    "                categorial_latent = torch.ones(batch_size).to(device) * category_mask_id\n",
    "\n",
    "                categorial_emb = encoder(categorial_latent.long()).float()\n",
    "                masked_emb.append(categorial_emb)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:\n",
    "                # create rand(0-1) as numerical latent\n",
    "                numerical_latent = torch.rand(batch_size).to(device)\n",
    "                numerical_latent = torch.unsqueeze(numerical_latent, dim = 1)\n",
    "                numerical_emb = numerical_latent.repeat(1, self.feature_emb_size)\n",
    "                masked_emb.append(numerical_emb)\n",
    "\n",
    "        masked_emb = torch.stack(masked_emb, dim = 1)\n",
    "        \n",
    "        ''' Positional Encoding for Mask '''\n",
    "        masked_emb = torch.cat([masked_emb, masked_pos_info], dim = 2) # (batch_size, num_mask_vars, feature_emb_size + pos_emb_size)\n",
    "\n",
    "        return unmasked_emb, masked_emb\n",
    "    \n",
    "    def decode(self, all_emb, unmask_mask_id):\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        unmask categorial\n",
    "        unmask numercial\n",
    "        mask categorial\n",
    "        mask numercial\n",
    "        '''\n",
    "            \n",
    "        # cols_id_name: {0: 'Gender', 1: 'Department', 2: 'Grade', 3: 'Extracurricular_Activities', \n",
    "        # 4: 'Internet_Access_at_Home', 5: 'Parent_Education_Level', 6: 'Family_Income_Level', \n",
    "        # 7: 'Attendance (%)', 8: 'Midterm_Score', 9: 'Final_Score', 10: 'Assignments_Avg', \n",
    "        # 11: 'Quizzes_Avg', 12: 'Projects_Score', 13: 'Total_Score', 14: 'Stress_Level (1-10)', \n",
    "        # 15: 'Sleep_Hours_per_Night', 16: 'Study_Hours_per_Week', 17: 'Age'}\n",
    "\n",
    "        batch_size, num_cols, hidden_size = all_emb.shape\n",
    "        device = all_emb.device\n",
    "        \n",
    "        ''' decode for unmask and mask '''\n",
    "        categorial_preds = []\n",
    "        numerical_preds = []\n",
    "        \n",
    "        categorial_col_name = []\n",
    "        numerical_col_name = []\n",
    "        \n",
    "        for c in range(num_cols):\n",
    "            # attribute value\n",
    "            attribute_value = all_emb[:, c, :]\n",
    "\n",
    "            # attribute id\n",
    "            attribute_id = unmask_mask_id[:, c]\n",
    "            assert len(torch.unique(attribute_id)) == 1, \"attribute_id in one small batch has to be the same\"\n",
    "            attribute_id = torch.unique(attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[attribute_id] in self.category_vars:\n",
    "                col_name = self.cols_id_name[attribute_id]\n",
    "                decoder = self.cat_decoders[col_name].to(device)\n",
    "                cat_pred = decoder(attribute_value)\n",
    "                categorial_preds.append(cat_pred)\n",
    "                categorial_col_name.append(col_name)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:\n",
    "                ori_attribute_value = attribute_value\n",
    "                \n",
    "                attribute_value = self.numerical_decoder1(attribute_value).to(device)\n",
    "                attribute_value = self.relu(attribute_value)\n",
    "                \n",
    "                attribute_value = self.numerical_decoder2(attribute_value).to(device)\n",
    "                attribute_value = self.relu(attribute_value)\n",
    "                \n",
    "                attribute_value = self.numerical_decoder3(attribute_value).to(device)\n",
    "                attribute_value = self.relu(attribute_value)\n",
    "                \n",
    "                attribute_value = self.numerical_decoder4(attribute_value).to(device)\n",
    "                attribute_value = self.relu(attribute_value)\n",
    "                \n",
    "                # residual connection\n",
    "                attribute_value = attribute_value + ori_attribute_value\n",
    "                \n",
    "                num_pred = self.numerical_decoder5(attribute_value).to(device)\n",
    "                numerical_preds.append(num_pred)\n",
    "                \n",
    "                col_name = self.cols_id_name[attribute_id]\n",
    "                numerical_col_name.append(col_name)\n",
    "\n",
    "        numerical_preds = torch.stack(numerical_preds, dim = 1)\n",
    "        numerical_preds = torch.squeeze(numerical_preds)\n",
    "    \n",
    "        return categorial_preds, numerical_preds, categorial_col_name, numerical_col_name\n",
    "    \n",
    "    \n",
    "    def reorder_label_fn(self, label, unmask_mask_id):\n",
    "        \n",
    "        batch_size, num_cols = label.shape\n",
    "        device = label.device\n",
    "        \n",
    "        ''' reorder for unmask and mask '''\n",
    "        categorial_labels = []\n",
    "        numerical_labels = []\n",
    "        \n",
    "        for c in range(num_cols):\n",
    "            # attribute value\n",
    "            attribute_value = label[:, c]\n",
    "\n",
    "            # attribute id\n",
    "            attribute_id = unmask_mask_id[:, c]\n",
    "            assert len(torch.unique(attribute_id)) == 1, \"attribute_id in one small batch has to be the same\"\n",
    "            attribute_id = torch.unique(attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[attribute_id] in self.category_vars:\n",
    "                categorial_labels.append(attribute_value)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:\n",
    "                numerical_labels.append(attribute_value)\n",
    "              \n",
    "        numerical_labels = torch.stack(numerical_labels, dim = 1)\n",
    "\n",
    "        return categorial_labels, numerical_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tableMET(nn.Module):\n",
    "    def __init__(self, position_emb_dim, layers_encode, layers_decode, num_head, num_variables, cols_name, category_vars, feature_emb_size, category_var_len, dropout):\n",
    "        super().__init__()\n",
    "        self.num_variables = num_variables\n",
    "        self.unmask_ratio = ((100 - MASK_RATIO) * num_variables) // 100\n",
    "        self.mask_ratio = num_variables - ((100 - MASK_RATIO) * num_variables) // 100\n",
    "\n",
    "        # feature embedding\n",
    "        self.feature_emb_fn = Feature_Embed(cols_name, category_vars, feature_emb_size, num_variables, position_emb_dim, category_var_len)\n",
    "\n",
    "        # encoder and decoder\n",
    "        self.transformer_encode = Transformer(position_emb_dim + feature_emb_size, layers_encode, num_head, dropout)\n",
    "        self.transformer_decode = Transformer(position_emb_dim + feature_emb_size, layers_decode, num_head, dropout)\n",
    "        \n",
    "    def forward(self, unmasked_data, unmasked_idx, masked_idx, label):\n",
    "        \n",
    "        ''' feature & position encoding for Unmask and Mask '''\n",
    "        # unmask_emb: [batch_size, num_unmask = 12, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 12, 64])\n",
    "        # mask_emb: [batch_size, num_mask = 6, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 6, 64])\n",
    "        unmask_emb, mask_emb = self.feature_emb_fn.encode(unmasked_data, unmasked_idx, masked_idx)\n",
    "        \n",
    "        # transformer (encoder) only for unmasked part\n",
    "        # unmask_emb: [batch_size, num_unmask = 12, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 12, 64])\n",
    "        unmask_emb = self.transformer_encode(unmask_emb)\n",
    "        \n",
    "        # combine unmask_emb and mask_emb\n",
    "        # all_emb: [batch_size, num_vars = 18, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 18, 64])\n",
    "        all_emb = torch.cat([unmask_emb, mask_emb], dim = 1)\n",
    "        \n",
    "        # transformer (decoder) for both unmasked and masked\n",
    "        # all_emb: [batch_size, num_vars = 18, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 18, 64])\n",
    "        all_emb = self.transformer_decode(all_emb)\n",
    "\n",
    "        ''' feature & position decoding for Unmask and Mask '''\n",
    "        unmask_mask_id = torch.cat([unmasked_idx, masked_idx], dim = 1)\n",
    "        categorial_preds, numerical_preds, categorial_col_name, numerical_col_name = self.feature_emb_fn.decode(all_emb, unmask_mask_id)\n",
    "\n",
    "        ''' reorder label: make label' variable order align as pred '''\n",
    "        categorial_labels, numerical_labels = self.feature_emb_fn.reorder_label_fn(label, unmask_mask_id)\n",
    "            \n",
    "\n",
    "        return categorial_preds, numerical_preds, categorial_labels, numerical_labels, categorial_col_name, numerical_col_name\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay_lr(lr_init, lr_final, num_warmup_steps, num_training_steps):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return current_step / num_warmup_steps \n",
    "        else:\n",
    "            progress = (current_step - num_warmup_steps) / (num_training_steps - num_warmup_steps)\n",
    "            return (1 - progress) * (1 - lr_final / lr_init) + (lr_final / lr_init)  \n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 1200 \n",
    "position_emb_dim = 512\n",
    "layers_encode = 6\n",
    "layers_decode = 2\n",
    "num_head = 8\n",
    "dropout = 0.3\n",
    "num_variables = 18\n",
    "unmask_ratio = ((100 - MASK_RATIO) * num_variables) // 100\n",
    "cols_name = processed_df_train.columns\n",
    "feature_emb_size = 512\n",
    "category_var_len = category_var_len\n",
    "\n",
    "is_power_of_two = lambda n: n > 0 and (n & (n - 1)) == 0\n",
    "assert is_power_of_two(position_emb_dim + feature_emb_size), \"position_emb_dim + feature_emb_size should be power term of 2\"\n",
    "\n",
    "model = tableMET(position_emb_dim, layers_encode, layers_decode, num_head, num_variables, cols_name, category_vars, feature_emb_size, category_var_len, dropout).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.95), eps=1e-6, weight_decay=1e-3)\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=linear_warmup_decay_lr(lr_init = LEARNING_RATE, lr_final = LEARNING_RATE * 1e-2, num_warmup_steps = 10, num_training_steps = EPOCHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss_fn = nn.MSELoss()\n",
    "CE_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label):\n",
    "    \n",
    "    num_numerical = 12\n",
    "    num_category = 7\n",
    "    ratio_numerical = num_numerical / (num_numerical + num_category)\n",
    "    ratio_category = 1 / (num_numerical + num_category)\n",
    "    \n",
    "    total_loss = torch.zeros(1).to(device)\n",
    "    \n",
    "    mse_loss = MSE_loss_fn(numerical_pred, numerical_label)\n",
    "    mse_loss = mse_loss * 1\n",
    "    total_loss += (mse_loss * ratio_numerical)\n",
    "    \n",
    "    for i in range(num_category):\n",
    "        pred = categorial_pred[i]\n",
    "        label = categorial_label[i]        \n",
    "        loss = CE_loss_fn(pred, label.long())\n",
    "        total_loss += (loss * ratio_category)\n",
    "        \n",
    "    return total_loss, mse_loss, (total_loss - mse_loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   0%|          | 0/1200 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical_preds: torch.Size([256, 11])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m latent \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m3\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m categorial_pred, numerical_pred, categorial_label, numerical_label, categorial_col_name, numerical_col_name \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43munmasked_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munmasked_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m loss, mse_loss, ce_loss \u001b[38;5;241m=\u001b[39m loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label)\n\u001b[1;32m     26\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/envs/Vit/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/Vit/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[18], line 36\u001b[0m, in \u001b[0;36mtableMET.forward\u001b[0;34m(self, unmasked_data, unmasked_idx, masked_idx, label)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' feature & position decoding for Unmask and Mask '''\u001b[39;00m\n\u001b[1;32m     35\u001b[0m unmask_mask_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([unmasked_idx, masked_idx], dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m categorial_preds, numerical_preds, categorial_col_name, numerical_col_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_emb_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munmask_mask_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m''' reorder label: make label' variable order align as pred '''\u001b[39;00m\n\u001b[1;32m     39\u001b[0m categorial_labels, numerical_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_emb_fn\u001b[38;5;241m.\u001b[39mreorder_label_fn(label, unmask_mask_id)\n",
      "Cell \u001b[0;32mIn[17], line 209\u001b[0m, in \u001b[0;36mFeature_Embed.decode\u001b[0;34m(self, all_emb, unmask_mask_id)\u001b[0m\n\u001b[1;32m    206\u001b[0m numerical_preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqueeze(numerical_preds)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumerical_preds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumerical_preds\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m categorial_preds, numerical_preds, categorial_col_name, numerical_col_name\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "train_LOSS = []\n",
    "valid_LOSS = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"iterate epoch\"):\n",
    "    \n",
    "    losses = []\n",
    "    mse_losses = []\n",
    "    ce_losses = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_mse_losses = []\n",
    "    val_ce_losses = []\n",
    "\n",
    "    model.train()\n",
    "    for data, label in train_dataloader:\n",
    "        unmasked_data = data[0].float().to(device)\n",
    "        unmasked_idx = data[1].long().to(device)\n",
    "        masked_idx = data[2].long().to(device)\n",
    "        latent = data[3].float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        \n",
    "        categorial_pred, numerical_pred, categorial_label, numerical_label, categorial_col_name, numerical_col_name = model(unmasked_data, unmasked_idx, masked_idx, label)\n",
    "        \n",
    "        loss, mse_loss, ce_loss = loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        mse_losses.append(mse_loss.item())\n",
    "        ce_losses.append(ce_loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    mse_losses = np.mean(mse_losses)\n",
    "    ce_losses = np.mean(ce_losses)\n",
    "    train_LOSS.append(losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'total variables are {num_variables}: first {unmask_ratio} unmasked, latter {num_variables - unmask_ratio}')\n",
    "        print(f\"epoch: {epoch}, loss: {losses}, mse: {mse_losses}, ce: {ce_losses}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, label in valid_dataloader:\n",
    "            unmasked_data = data[0].float().to(device)\n",
    "            unmasked_idx = data[1].long().to(device)\n",
    "            masked_idx = data[2].long().to(device)\n",
    "            latent = data[3].float().to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            categorial_pred, numerical_pred, categorial_label, numerical_label, categorial_col_name, numerical_col_name = model(unmasked_data, unmasked_idx, masked_idx, label)\n",
    "            \n",
    "            loss, mse_loss, ce_loss = loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_mse_losses.append(mse_loss.item())\n",
    "            val_ce_losses.append(ce_loss)            \n",
    "            \n",
    "    val_losses = np.mean(val_losses)\n",
    "    val_mse_losses = np.mean(val_mse_losses)\n",
    "    val_ce_losses = np.mean(val_ce_losses)\n",
    "    valid_LOSS.append(val_losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"epoch: {epoch}, val_loss: {val_losses}, val_mse: {val_mse_losses}, val_ce_losses: {val_ce_losses}\")\n",
    "        print()        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_LOSS)), train_LOSS, color = 'blue')\n",
    "plt.plot(range(len(valid_LOSS)), valid_LOSS, color = 'red')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_norm(df):\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    # Category \n",
    "    for cat_name in category_vars:\n",
    "        cat_var = df[cat_name]\n",
    "        new_df[f'{cat_name}'] = cat_var\n",
    "    \n",
    "    # Numerical score\n",
    "    for num_name in numerical_score_vars:\n",
    "        num_var = df[num_name]\n",
    "        \n",
    "        # reverse (0 - 100) min max norm\n",
    "        num_var = (num_var * 100) + 0\n",
    "        \n",
    "        new_df[num_name] = num_var.values\n",
    "    \n",
    "    # Numerical scalar\n",
    "    for num_name in numerical_scalar_vars:\n",
    "        num_var = df[num_name]\n",
    "        \n",
    "        # reverse (0 - 10) min max norm\n",
    "        num_var = (num_var * 10) + 0\n",
    "        # reverse\n",
    "        num_var = np.exp(num_var)\n",
    "        new_df[num_name] = num_var.values\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sample_id = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmasked_idx_one = np.array(unmasked_idx[select_sample_id].detach().cpu(), dtype=int)\n",
    "masked_idx_one = np.array(masked_idx[select_sample_id].detach().cpu(), dtype=int)\n",
    "\n",
    "\n",
    "categorial_pred_one = []\n",
    "for pred in categorial_pred:\n",
    "    argmax_pred = torch.argmax(pred, dim = 1)\n",
    "    categorial_pred_one.append(argmax_pred)\n",
    "categorial_pred_one = torch.stack(categorial_pred_one, dim = 1)\n",
    "categorial_pred_one = np.array(categorial_pred_one[select_sample_id].detach().cpu())\n",
    "\n",
    "categorial_label_one = torch.stack(categorial_label, dim = 1)\n",
    "categorial_label_one = np.array(categorial_label_one[select_sample_id].detach().cpu())\n",
    "\n",
    "numerical_pred_one = np.array(numerical_pred[select_sample_id].detach().cpu())\n",
    "numerical_label_one = np.array(numerical_label[select_sample_id].detach().cpu())\n",
    "\n",
    "\n",
    "print(f\"categorial_pred_one: {categorial_pred_one.shape}\")\n",
    "print(f\"categorial_label_one: {categorial_label_one.shape}\")\n",
    "print(f\"numerical_pred_one: {numerical_pred_one.shape}\")\n",
    "print(f\"numerical_label_one: {numerical_label_one.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concat([categorial_pred_one, numerical_pred_one], axis = 0)\n",
    "label = np.concat([categorial_label_one, numerical_label_one], axis = 0)\n",
    "\n",
    "res = pd.DataFrame([pred, label], columns = categorial_col_name + numerical_col_name)\n",
    "reverse_res = reverse_norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_res[cols_name[masked_idx_one]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_res[cols_name[unmasked_idx_one]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars\n",
    "# ['Study_Hours_per_Week', 'Age', 'Stress_Level (1-10)', 'Sleep_Hours_per_Night']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
