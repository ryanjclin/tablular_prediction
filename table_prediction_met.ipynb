{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Students_Grading_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually select Cols (attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>52.29</td>\n",
       "      <td>55.03</td>\n",
       "      <td>57.82</td>\n",
       "      <td>84.22</td>\n",
       "      <td>74.06</td>\n",
       "      <td>85.90</td>\n",
       "      <td>56.09</td>\n",
       "      <td>F</td>\n",
       "      <td>6.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.23</td>\n",
       "      <td>45.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.24</td>\n",
       "      <td>55.65</td>\n",
       "      <td>50.64</td>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Business</td>\n",
       "      <td>57.19</td>\n",
       "      <td>67.05</td>\n",
       "      <td>93.68</td>\n",
       "      <td>67.70</td>\n",
       "      <td>85.70</td>\n",
       "      <td>73.79</td>\n",
       "      <td>70.30</td>\n",
       "      <td>D</td>\n",
       "      <td>20.7</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>95.15</td>\n",
       "      <td>47.79</td>\n",
       "      <td>80.63</td>\n",
       "      <td>66.06</td>\n",
       "      <td>93.51</td>\n",
       "      <td>92.12</td>\n",
       "      <td>61.63</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>54.18</td>\n",
       "      <td>46.59</td>\n",
       "      <td>78.89</td>\n",
       "      <td>96.85</td>\n",
       "      <td>83.70</td>\n",
       "      <td>68.42</td>\n",
       "      <td>66.13</td>\n",
       "      <td>F</td>\n",
       "      <td>15.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.15</td>\n",
       "      <td>60.33</td>\n",
       "      <td>80.09</td>\n",
       "      <td>99.32</td>\n",
       "      <td>58.42</td>\n",
       "      <td>85.21</td>\n",
       "      <td>D</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Low</td>\n",
       "      <td>10</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>65.11</td>\n",
       "      <td>86.31</td>\n",
       "      <td>49.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.08</td>\n",
       "      <td>60.87</td>\n",
       "      <td>95.96</td>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>CS</td>\n",
       "      <td>87.54</td>\n",
       "      <td>63.55</td>\n",
       "      <td>64.21</td>\n",
       "      <td>94.28</td>\n",
       "      <td>50.19</td>\n",
       "      <td>82.65</td>\n",
       "      <td>54.25</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>92.56</td>\n",
       "      <td>79.79</td>\n",
       "      <td>94.28</td>\n",
       "      <td>81.20</td>\n",
       "      <td>61.18</td>\n",
       "      <td>94.29</td>\n",
       "      <td>55.84</td>\n",
       "      <td>A</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>83.92</td>\n",
       "      <td>83.24</td>\n",
       "      <td>53.47</td>\n",
       "      <td>51.76</td>\n",
       "      <td>83.51</td>\n",
       "      <td>69.25</td>\n",
       "      <td>77.86</td>\n",
       "      <td>F</td>\n",
       "      <td>29.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age   Department  Attendance (%)  Midterm_Score  Final_Score  \\\n",
       "0     Female   22  Engineering           52.29          55.03        57.82   \n",
       "1       Male   18  Engineering           97.27          97.23        45.80   \n",
       "2       Male   24     Business           57.19          67.05        93.68   \n",
       "3     Female   24  Mathematics           95.15          47.79        80.63   \n",
       "4     Female   23           CS           54.18          46.59        78.89   \n",
       "...      ...  ...          ...             ...            ...          ...   \n",
       "4995    Male   19     Business             NaN          82.15        60.33   \n",
       "4996    Male   19     Business           65.11          86.31        49.80   \n",
       "4997  Female   24           CS           87.54          63.55        64.21   \n",
       "4998    Male   23           CS           92.56          79.79        94.28   \n",
       "4999  Female   21  Engineering           83.92          83.24        53.47   \n",
       "\n",
       "      Assignments_Avg  Quizzes_Avg  Projects_Score  Total_Score Grade  \\\n",
       "0               84.22        74.06           85.90        56.09     F   \n",
       "1                 NaN        94.24           55.65        50.64     A   \n",
       "2               67.70        85.70           73.79        70.30     D   \n",
       "3               66.06        93.51           92.12        61.63     A   \n",
       "4               96.85        83.70           68.42        66.13     F   \n",
       "...               ...          ...             ...          ...   ...   \n",
       "4995            80.09        99.32           58.42        85.21     D   \n",
       "4996              NaN        88.08           60.87        95.96     C   \n",
       "4997            94.28        50.19           82.65        54.25     A   \n",
       "4998            81.20        61.18           94.29        55.84     A   \n",
       "4999            51.76        83.51           69.25        77.86     F   \n",
       "\n",
       "      Study_Hours_per_Week Extracurricular_Activities Internet_Access_at_Home  \\\n",
       "0                      6.2                         No                     Yes   \n",
       "1                     19.0                         No                     Yes   \n",
       "2                     20.7                         No                     Yes   \n",
       "3                     24.8                        Yes                     Yes   \n",
       "4                     15.4                        Yes                     Yes   \n",
       "...                    ...                        ...                     ...   \n",
       "4995                  25.5                         No                     Yes   \n",
       "4996                   5.0                         No                     Yes   \n",
       "4997                  24.8                        Yes                      No   \n",
       "4998                  16.1                        Yes                     Yes   \n",
       "4999                  29.2                         No                     Yes   \n",
       "\n",
       "     Parent_Education_Level Family_Income_Level  Stress_Level (1-10)  \\\n",
       "0               High School              Medium                    5   \n",
       "1                       NaN              Medium                    4   \n",
       "2                  Master's                 Low                    6   \n",
       "3               High School                High                    3   \n",
       "4               High School                High                    2   \n",
       "...                     ...                 ...                  ...   \n",
       "4995            High School                 Low                   10   \n",
       "4996                    NaN              Medium                    4   \n",
       "4997            High School              Medium                    4   \n",
       "4998             Bachelor's                 Low                    1   \n",
       "4999                    PhD                 Low                    2   \n",
       "\n",
       "      Sleep_Hours_per_Night  \n",
       "0                       4.7  \n",
       "1                       9.0  \n",
       "2                       6.2  \n",
       "3                       6.7  \n",
       "4                       7.1  \n",
       "...                     ...  \n",
       "4995                    8.3  \n",
       "4996                    4.0  \n",
       "4997                    6.3  \n",
       "4998                    8.4  \n",
       "4999                    6.1  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unimportant_attribute = ['Student_ID', 'First_Name', 'Last_Name', 'Email', 'Participation_Score']\n",
    "\n",
    "filtered_df = df.drop(unimportant_attribute, axis=1)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "# numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score', 'Stress_Level (1-10)']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate rows with-Nan and without-Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row with Nan: (2419, 18)\n",
      "row without Nan: (2581, 18)\n"
     ]
    }
   ],
   "source": [
    "nan_rows = filtered_df.isna().any(axis=1)\n",
    "\n",
    "# Nan rows\n",
    "df_nan = filtered_df[nan_rows]\n",
    "print(f\"row with Nan: {df_nan.shape}\")\n",
    "\n",
    "# Complete rows\n",
    "df_complete = filtered_df[~nan_rows]\n",
    "print(f\"row without Nan: {df_complete.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: (1806, 18)\n",
      "df_valid: (775, 18)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid, _, _ = train_test_split(df_complete, df_complete, test_size=0.3, random_state=0)\n",
    "\n",
    "df_train_id = [i for i in range(len(df_train))]\n",
    "df_valid_id = [i for i in range(len(df_valid))]\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_valid: {df_valid.shape}\")\n",
    "\n",
    "# print(f\"df_train_id: {df_train_id}\")\n",
    "# print(f\"df_valid_id: {df_valid_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: \n",
    "1. category to numerical\n",
    "2. max-min norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_to_numerical(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data)\n",
    "    num_data = le.transform(data)\n",
    "    \n",
    "    return num_data, le\n",
    "\n",
    "def max_min_norm_score(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "    \n",
    "def max_min_norm_scalar(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "\n",
    "    \n",
    "def preprocessing(df, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        train_params = {}\n",
    "        category_var_len = {}\n",
    "\n",
    "    # Category \n",
    "    for cat_name in category_vars:\n",
    "        cat_var = df[cat_name]\n",
    "        if process_type == 'train':\n",
    "            cat_var, le = category_to_numerical(cat_var)\n",
    "            train_params[f'{cat_name}_le'] = le\n",
    "            category_var_len[f'{cat_name}'] = len(np.unique(cat_var))\n",
    "        else:\n",
    "            cat_var = train_params[f'{cat_name}_le'].transform(cat_var)\n",
    "        new_df[f'{cat_name}'] = cat_var\n",
    "    \n",
    "    # Numerical score\n",
    "    for num_name in numerical_score_vars:\n",
    "        num_var = df[num_name]\n",
    "        # if process_type == 'train':\n",
    "        #     num_var, data_max, data_min = max_min_norm_score(num_var, process_type = 'train')\n",
    "        #     train_params[num_name] = [data_max, data_min]\n",
    "        # else:\n",
    "        #     num_var = max_min_norm_score(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "    \n",
    "    # Numerical scalar\n",
    "    for num_name in numerical_scalar_vars:\n",
    "        num_var = df[num_name]\n",
    "        # num_var = np.log(num_var)\n",
    "        # if process_type == 'train':\n",
    "        #     num_var, data_max, data_min = max_min_norm_scalar(num_var, process_type = 'train')\n",
    "        #     train_params[num_name] = [data_max, data_min]\n",
    "        # else:\n",
    "        #     num_var = max_min_norm_scalar(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "        \n",
    "        \n",
    "    if process_type == 'train':\n",
    "        return new_df, train_params, category_var_len\n",
    "    else:\n",
    "        return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_var_len: {'Gender': 2, 'Department': 4, 'Grade': 5, 'Extracurricular_Activities': 2, 'Internet_Access_at_Home': 2, 'Parent_Education_Level': 4, 'Family_Income_Level': 3}\n",
      "processed_df_train: (1806, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.89</td>\n",
       "      <td>42.55</td>\n",
       "      <td>50.45</td>\n",
       "      <td>55.28</td>\n",
       "      <td>76.34</td>\n",
       "      <td>57.83</td>\n",
       "      <td>74.26</td>\n",
       "      <td>27.8</td>\n",
       "      <td>24</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>55.62</td>\n",
       "      <td>81.90</td>\n",
       "      <td>45.43</td>\n",
       "      <td>53.80</td>\n",
       "      <td>92.15</td>\n",
       "      <td>63.71</td>\n",
       "      <td>89.95</td>\n",
       "      <td>5.9</td>\n",
       "      <td>23</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>63.09</td>\n",
       "      <td>60.57</td>\n",
       "      <td>56.80</td>\n",
       "      <td>53.42</td>\n",
       "      <td>82.88</td>\n",
       "      <td>56.71</td>\n",
       "      <td>59.43</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19</td>\n",
       "      <td>4.9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60.77</td>\n",
       "      <td>98.69</td>\n",
       "      <td>45.50</td>\n",
       "      <td>57.71</td>\n",
       "      <td>53.39</td>\n",
       "      <td>55.16</td>\n",
       "      <td>83.37</td>\n",
       "      <td>16.8</td>\n",
       "      <td>19</td>\n",
       "      <td>8.2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>95.90</td>\n",
       "      <td>84.59</td>\n",
       "      <td>68.58</td>\n",
       "      <td>52.04</td>\n",
       "      <td>63.89</td>\n",
       "      <td>65.54</td>\n",
       "      <td>88.54</td>\n",
       "      <td>6.3</td>\n",
       "      <td>21</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           1      1                           1   \n",
       "1       1           3      2                           0   \n",
       "2       1           1      4                           0   \n",
       "3       1           2      2                           1   \n",
       "4       0           2      1                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       0                    1   \n",
       "1                        1                       3                    2   \n",
       "2                        1                       1                    1   \n",
       "3                        1                       1                    2   \n",
       "4                        1                       1                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0           89.89          42.55        50.45            55.28        76.34   \n",
       "1           55.62          81.90        45.43            53.80        92.15   \n",
       "2           63.09          60.57        56.80            53.42        82.88   \n",
       "3           60.77          98.69        45.50            57.71        53.39   \n",
       "4           95.90          84.59        68.58            52.04        63.89   \n",
       "\n",
       "   Projects_Score  Total_Score  Study_Hours_per_Week  Age  \\\n",
       "0           57.83        74.26                  27.8   24   \n",
       "1           63.71        89.95                   5.9   23   \n",
       "2           56.71        59.43                  18.9   19   \n",
       "3           55.16        83.37                  16.8   19   \n",
       "4           65.54        88.54                   6.3   21   \n",
       "\n",
       "   Sleep_Hours_per_Night  Stress_Level (1-10)  \n",
       "0                    8.4                    4  \n",
       "1                    6.9                    2  \n",
       "2                    4.9                    7  \n",
       "3                    8.2                   10  \n",
       "4                    8.9                    6  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_train, train_params, category_var_len = preprocessing(df_train, process_type = 'train')\n",
    "# train_params\n",
    "print(f\"category_var_len: {category_var_len}\")\n",
    "print(f\"processed_df_train: {processed_df_train.shape}\")\n",
    "\n",
    "cols_name = processed_df_train.columns\n",
    "processed_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_df_valid: (775, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51.54</td>\n",
       "      <td>64.04</td>\n",
       "      <td>50.02</td>\n",
       "      <td>87.28</td>\n",
       "      <td>96.99</td>\n",
       "      <td>82.58</td>\n",
       "      <td>88.88</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>99.70</td>\n",
       "      <td>93.76</td>\n",
       "      <td>61.42</td>\n",
       "      <td>54.57</td>\n",
       "      <td>75.76</td>\n",
       "      <td>53.97</td>\n",
       "      <td>64.68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>18</td>\n",
       "      <td>4.1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61.51</td>\n",
       "      <td>73.15</td>\n",
       "      <td>41.90</td>\n",
       "      <td>55.37</td>\n",
       "      <td>55.64</td>\n",
       "      <td>78.62</td>\n",
       "      <td>54.29</td>\n",
       "      <td>19.1</td>\n",
       "      <td>24</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>52.28</td>\n",
       "      <td>82.12</td>\n",
       "      <td>99.62</td>\n",
       "      <td>55.18</td>\n",
       "      <td>50.23</td>\n",
       "      <td>83.34</td>\n",
       "      <td>65.64</td>\n",
       "      <td>24.4</td>\n",
       "      <td>21</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>94.74</td>\n",
       "      <td>53.40</td>\n",
       "      <td>62.16</td>\n",
       "      <td>83.29</td>\n",
       "      <td>79.03</td>\n",
       "      <td>62.50</td>\n",
       "      <td>65.57</td>\n",
       "      <td>10.6</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           3      2                           0   \n",
       "1       1           1      1                           1   \n",
       "2       1           3      2                           0   \n",
       "3       1           1      3                           1   \n",
       "4       1           2      0                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       2                    1   \n",
       "1                        1                       2                    1   \n",
       "2                        1                       3                    0   \n",
       "3                        1                       2                    1   \n",
       "4                        1                       0                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0           51.54          64.04        50.02            87.28        96.99   \n",
       "1           99.70          93.76        61.42            54.57        75.76   \n",
       "2           61.51          73.15        41.90            55.37        55.64   \n",
       "3           52.28          82.12        99.62            55.18        50.23   \n",
       "4           94.74          53.40        62.16            83.29        79.03   \n",
       "\n",
       "   Projects_Score  Total_Score  Study_Hours_per_Week  Age  \\\n",
       "0           82.58        88.88                  17.1   19   \n",
       "1           53.97        64.68                   7.0   18   \n",
       "2           78.62        54.29                  19.1   24   \n",
       "3           83.34        65.64                  24.4   21   \n",
       "4           62.50        65.57                  10.6   23   \n",
       "\n",
       "   Sleep_Hours_per_Night  Stress_Level (1-10)  \n",
       "0                    8.5                    8  \n",
       "1                    4.1                    8  \n",
       "2                    6.9                    9  \n",
       "3                    6.4                    7  \n",
       "4                    7.4                    3  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_valid = preprocessing(df_valid, train_params, process_type = 'valid')\n",
    "print(f\"processed_df_valid: {processed_df_valid.shape}\")\n",
    "processed_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "MASK_RATIO = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_helper(data, MASK_RATIO, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    rows, cols = data.shape\n",
    "    \n",
    "    # define mask/unmask ratio\n",
    "    unmask_ratio = ((100 - MASK_RATIO) * cols) // 100\n",
    "    mask_ratio = cols - unmask_ratio\n",
    "\n",
    "    # create random index\n",
    "    shuff_idx = np.array([np.random.permutation(cols) for _ in range(rows)])\n",
    "    \n",
    "    # define mask/unmask idx\n",
    "    mask_idx = shuff_idx[:, :mask_ratio]\n",
    "    unmask_idx = shuff_idx[:, mask_ratio:]\n",
    "    \n",
    "    mask_idx.sort(axis=1)\n",
    "    unmask_idx.sort(axis=1)\n",
    "    \n",
    "    # create new_data (contain unmask cols, but remove mask cols)\n",
    "    new_data = np.zeros((rows, unmask_ratio))\n",
    "    for i in range(rows):\n",
    "        new_data[i] = data[i][unmask_idx[i]]\n",
    "        \n",
    "    return new_data, unmask_idx, mask_idx, unmask_ratio\n",
    "\n",
    "def masking_fn(data, seed):\n",
    "    sample_size = len(data)\n",
    "\n",
    "    new_data, unmask_idx, mask_idx, unmask_ratio = masking_helper(data, MASK_RATIO, seed)\n",
    "        \n",
    "    X = [[],[],[],[]]\n",
    "    Y = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        X[0].append(new_data[i]) # unmask data\n",
    "        X[1].append(unmask_idx[i]) # unmask id\n",
    "        X[2].append(mask_idx[i]) # mask id\n",
    "        X[3].append(np.ones(unmask_ratio)) # len = unmask, serve as random noisee in VAE\n",
    "        Y.append(data[i][list(unmask_idx[i])+list(mask_idx[i])]) # label (unmask + mask)\n",
    "\n",
    "    X[0] = torch.tensor(np.array(X[0])) # unmask data\n",
    "    X[1] = torch.tensor(np.array(X[1])) # unmask id\n",
    "    X[2] = torch.tensor(np.array(X[2])) # mask id\n",
    "    X[3] = torch.tensor(np.array(X[3])) # latent space\n",
    "    \n",
    "    Y = torch.tensor(np.array(Y))\n",
    "    \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(data_wtih_type):\n",
    "\n",
    "    # data\n",
    "    data = [dat[0] for dat in data_wtih_type]\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # data type: training/valid\n",
    "    data_type = data_wtih_type[0][1]\n",
    "\n",
    "    if data_type == 'training':\n",
    "        seed = np.random.randint(5, size=1)\n",
    "    else:\n",
    "        seed = 42\n",
    "\n",
    "    data, label = masking_fn(data, seed)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(self, data, data_type = 'training'):\n",
    "        self.data = data\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        dat = self.data.iloc[id, :]\n",
    "        dat = np.array(dat)\n",
    "        return dat, self.data_type\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "augmented_processed_df_train = pd.concat([processed_df_train, processed_df_train, processed_df_train], axis = 0)\n",
    "train_dataset = TableDataset(augmented_processed_df_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=4, shuffle=False, collate_fn = collate_fn_train)\n",
    "\n",
    "\n",
    "valid_dataset = TableDataset(processed_df_valid, data_type = 'valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn = collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class positional_encoder(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, num_variables):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_emb_dim = encoder_emb_dim\n",
    "        self.pos_emb = nn.Embedding(num_variables, encoder_emb_dim)\n",
    "        \n",
    "    def forward(self, unmasked_data, unmasked_idx, masked_idx):\n",
    "        \n",
    "        unmasked_pos_info = self.pos_emb(unmasked_idx.long()).float()\n",
    "\n",
    "        masked_pos_info = self.pos_emb(masked_idx.long()).float()\n",
    "\n",
    "        unmasked_data = torch.unsqueeze(unmasked_data, dim = 2) # (batch_size, num_vars, 1)\n",
    "        unmasked_data_w_pos = torch.cat([unmasked_data, unmasked_pos_info], dim = 2) # (batch_size, num_vars, 1 + encoder_emb_dim)\n",
    "        \n",
    "        return unmasked_data_w_pos, masked_pos_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, num_head, encoder_emb_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.num_head = num_head\n",
    "        self.encoder_emb_dim = encoder_emb_dim\n",
    "\n",
    "        # up_emb_size * 3 for qkv\n",
    "        self.qkv_fn = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim * 3, bias=False)\n",
    "        self.proj_qkv = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim, bias = False)\n",
    "                \n",
    "        # other\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        batch_size, num_vars, _ = x.shape\n",
    "\n",
    "        # qkv: up_emb_size * 3\n",
    "        x = self.qkv_fn(x) \n",
    "        q, k, v = x.split(self.encoder_emb_dim, dim = 2) \n",
    "        \n",
    "        # split head: each shape = [batch_size, num_head, num_vars(seq_len), head_size = 8]\n",
    "        q = q.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        k = k.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        v = v.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        \n",
    "        # attention matrix calculation: [batch_size, num_head, num_vars(seq_len), num_vars]\n",
    "        att = (q @ k.transpose(-2,-1)) * (1 / torch.sqrt(torch.ones([1]).to(device) * k.size(-1)))\n",
    "        att = F.softmax(att, dim = -1)\n",
    "        att = self.att_dropout(att)\n",
    "        \n",
    "        # att matrix * V: [batch_size, num_head, num_vars(seq_len), head_size]\n",
    "        out = att @ v\n",
    "        out = out.transpose(1,2).contiguous().view(batch_size, num_vars, self.encoder_emb_dim)\n",
    "        out = self.proj_qkv(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, transformer_emb_size):\n",
    "        super().__init__()\n",
    "        self.up    = nn.Linear(transformer_emb_size, transformer_emb_size * 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.down  = nn.Linear(transformer_emb_size * 3, transformer_emb_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.down(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, num_head, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        self.ln_head = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.head = Head(num_head, encoder_emb_dim, dropout)\n",
    "        self.dropout_head = nn.Dropout(dropout)\n",
    "\n",
    "        self.ln_mlp = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.mlp = MLP(encoder_emb_dim)\n",
    "        self.dropout_mlp = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # att \n",
    "        ori_x = x \n",
    "        x = self.head(x)\n",
    "        x = self.dropout_head(x)\n",
    "        x = self.ln_head(ori_x + x)\n",
    "        \n",
    "        # linear \n",
    "        ori_x = x \n",
    "        x = self.mlp(x)\n",
    "        x = self.dropout_mlp(x)\n",
    "        x = self.ln_mlp(ori_x + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(Block(encoder_emb_dim, num_head, dropout) for _ in range(layers))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tableMET(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, layers_encode, layers_decode, num_head, num_variables, dropout):\n",
    "        super().__init__()\n",
    "        self.num_variables = num_variables\n",
    "        self.unmask_ratio = ((100 - MASK_RATIO) * num_variables) // 100\n",
    "        self.mask_ratio = num_variables - ((100 - MASK_RATIO) * num_variables) // 100\n",
    "\n",
    "        # positional embedding \n",
    "        self.encoder = positional_encoder(encoder_emb_dim, num_variables)\n",
    "        \n",
    "        # encoder and decoder\n",
    "        self.transformer_encode = Transformer(encoder_emb_dim + 1, layers_encode, num_head, dropout)\n",
    "        self.transformer_decode = Transformer(encoder_emb_dim + 1, layers_decode, num_head, dropout)\n",
    "\n",
    "        # linear for latent space\n",
    "        self.latent_fn = nn.Linear(self.unmask_ratio, 1)\n",
    "\n",
    "        # final linear convert emb back into 1\n",
    "        self.proj = nn.Linear(encoder_emb_dim + 1, 1)\n",
    "        \n",
    "    def forward(self, unmasked_data, unmasked_idx, masked_idx, latent):\n",
    "        \n",
    "        # positional emcoding \n",
    "        unmasked_emb, masked_pos_info = self.encoder(unmasked_data, unmasked_idx, masked_idx)\n",
    "\n",
    "        # transformer (encoder) only for unmasked part\n",
    "        unmasked_emb = self.transformer_encode(unmasked_emb)\n",
    "\n",
    "        # latent space process\n",
    "        latent = self.latent_fn(latent)\n",
    "        latent = torch.unsqueeze(latent, dim = 1)\n",
    "        latent = latent.repeat(1, self.mask_ratio, 1)\n",
    "        mask_emb = torch.cat([latent, masked_pos_info], dim = 2)\n",
    "\n",
    "        # combine unmask_emb and mask_emb\n",
    "        all_emb = torch.cat([unmasked_emb, mask_emb], dim = 1)\n",
    "\n",
    "        # transformer (decoder) for both unmasked and masked\n",
    "        unmasked_emb = self.transformer_encode(all_emb)\n",
    "\n",
    "        # project emb from embedding space back into 1 (original feature space)\n",
    "        out = self.proj(unmasked_emb)\n",
    "        out = torch.squeeze(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay_lr(lr_init, lr_final, num_warmup_steps, num_training_steps):\n",
    "    \"\"\"\n",
    "    Returns a lambda function for LambdaLR.\n",
    "    - lr_init: 初始學習率\n",
    "    - lr_final: 最終學習率（不是 0）\n",
    "    - num_warmup_steps: 預熱步數\n",
    "    - num_training_steps: 總訓練步數\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return current_step / num_warmup_steps  # 線性預熱\n",
    "        else:\n",
    "            progress = (current_step - num_warmup_steps) / (num_training_steps - num_warmup_steps)\n",
    "            return (1 - progress) * (1 - lr_final / lr_init) + (lr_final / lr_init)  # 線性衰減到 lr_final\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 2000\n",
    "encoder_emb_dim = 64\n",
    "layers_encode = 6\n",
    "layers_decode = 2\n",
    "num_head = 1\n",
    "dropout = 0.3\n",
    "num_variables = 18\n",
    "unmask_ratio = ((100 - MASK_RATIO) * num_variables) // 100\n",
    "\n",
    "\n",
    "\n",
    "model = tableMET(encoder_emb_dim, layers_encode, layers_decode, num_head, num_variables, dropout).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.95), eps=1e-6, weight_decay=1e-3)\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=linear_warmup_decay_lr(lr_init = LEARNING_RATE, lr_final = LEARNING_RATE * 1e-2, num_warmup_steps = 10, num_training_steps = EPOCHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   0%|          | 1/2000 [00:01<38:49,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 0, loss: 2273.3685191761365, num_train_sample: 22\n",
      "epoch: 0, val_loss: 2340.2654418945312, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   3%|▎         | 51/2000 [00:54<34:50,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 50, loss: 1562.624267578125, num_train_sample: 22\n",
      "epoch: 50, val_loss: 1608.7869567871094, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   5%|▌         | 101/2000 [02:02<42:21,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 100, loss: 1048.9265858043325, num_train_sample: 22\n",
      "epoch: 100, val_loss: 1084.2080078125, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   8%|▊         | 151/2000 [03:00<32:50,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 150, loss: 614.3924699263139, num_train_sample: 22\n",
      "epoch: 150, val_loss: 637.3595886230469, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  10%|█         | 201/2000 [03:54<32:47,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 200, loss: 224.271540555087, num_train_sample: 22\n",
      "epoch: 200, val_loss: 236.9947395324707, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  13%|█▎        | 251/2000 [04:48<31:22,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 250, loss: 93.46808728304777, num_train_sample: 22\n",
      "epoch: 250, val_loss: 94.4640007019043, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  15%|█▌        | 301/2000 [05:41<30:08,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 300, loss: 36.25982856750488, num_train_sample: 22\n",
      "epoch: 300, val_loss: 36.22468566894531, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  18%|█▊        | 351/2000 [06:35<28:53,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 350, loss: 33.244886831803754, num_train_sample: 22\n",
      "epoch: 350, val_loss: 33.76628589630127, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  20%|██        | 401/2000 [07:29<28:33,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 400, loss: 32.398658752441406, num_train_sample: 22\n",
      "epoch: 400, val_loss: 33.48322153091431, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  23%|██▎       | 451/2000 [08:22<27:22,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 450, loss: 32.364785714582965, num_train_sample: 22\n",
      "epoch: 450, val_loss: 33.442296504974365, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  25%|██▌       | 501/2000 [09:16<26:38,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 500, loss: 32.42755274339156, num_train_sample: 22\n",
      "epoch: 500, val_loss: 33.3515739440918, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  28%|██▊       | 551/2000 [10:10<25:31,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 550, loss: 31.994449268687855, num_train_sample: 22\n",
      "epoch: 550, val_loss: 32.61070680618286, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  30%|███       | 601/2000 [11:04<25:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 600, loss: 31.47881473194469, num_train_sample: 22\n",
      "epoch: 600, val_loss: 32.31589126586914, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  33%|███▎      | 651/2000 [11:58<24:01,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 650, loss: 31.25196110118519, num_train_sample: 22\n",
      "epoch: 650, val_loss: 32.58854627609253, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  35%|███▌      | 701/2000 [12:51<23:14,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 700, loss: 30.948675935918633, num_train_sample: 22\n",
      "epoch: 700, val_loss: 32.43081474304199, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  38%|███▊      | 751/2000 [13:45<21:47,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 750, loss: 30.7189677845348, num_train_sample: 22\n",
      "epoch: 750, val_loss: 32.332791805267334, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  40%|████      | 801/2000 [14:39<21:48,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 800, loss: 30.44740711558949, num_train_sample: 22\n",
      "epoch: 800, val_loss: 32.03931665420532, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  43%|████▎     | 851/2000 [15:33<20:54,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 850, loss: 31.078223141756926, num_train_sample: 22\n",
      "epoch: 850, val_loss: 32.52637004852295, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  45%|████▌     | 901/2000 [16:27<19:31,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 900, loss: 30.869006503712047, num_train_sample: 22\n",
      "epoch: 900, val_loss: 32.3915638923645, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  48%|████▊     | 951/2000 [17:21<18:50,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 950, loss: 30.631637833335184, num_train_sample: 22\n",
      "epoch: 950, val_loss: 32.19610786437988, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  50%|█████     | 1001/2000 [18:14<17:50,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1000, loss: 31.070114742625844, num_train_sample: 22\n",
      "epoch: 1000, val_loss: 32.162548542022705, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  53%|█████▎    | 1051/2000 [19:08<17:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1050, loss: 30.815827803178266, num_train_sample: 22\n",
      "epoch: 1050, val_loss: 32.08195877075195, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  55%|█████▌    | 1101/2000 [20:02<16:24,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1100, loss: 30.61350883137096, num_train_sample: 22\n",
      "epoch: 1100, val_loss: 32.10216569900513, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  58%|█████▊    | 1151/2000 [20:56<14:40,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1150, loss: 30.801350420171563, num_train_sample: 22\n",
      "epoch: 1150, val_loss: 32.225749015808105, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  60%|██████    | 1201/2000 [21:49<14:19,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1200, loss: 30.189371542497113, num_train_sample: 22\n",
      "epoch: 1200, val_loss: 32.15624761581421, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  63%|██████▎   | 1251/2000 [22:43<13:38,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1250, loss: 30.644234917380594, num_train_sample: 22\n",
      "epoch: 1250, val_loss: 32.27229404449463, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  65%|██████▌   | 1301/2000 [23:37<12:23,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1300, loss: 30.716715119101785, num_train_sample: 22\n",
      "epoch: 1300, val_loss: 32.089237213134766, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  68%|██████▊   | 1351/2000 [24:31<11:28,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1350, loss: 31.15267562866211, num_train_sample: 22\n",
      "epoch: 1350, val_loss: 32.15313911437988, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  70%|███████   | 1401/2000 [25:24<10:42,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1400, loss: 30.165658083829012, num_train_sample: 22\n",
      "epoch: 1400, val_loss: 32.0352783203125, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  73%|███████▎  | 1451/2000 [26:16<10:01,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1450, loss: 30.40984500538219, num_train_sample: 22\n",
      "epoch: 1450, val_loss: 32.04819202423096, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  75%|███████▌  | 1501/2000 [27:09<09:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1500, loss: 30.696696801619098, num_train_sample: 22\n",
      "epoch: 1500, val_loss: 32.02051782608032, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  78%|███████▊  | 1551/2000 [28:03<08:06,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1550, loss: 30.8241849379106, num_train_sample: 22\n",
      "epoch: 1550, val_loss: 32.07901859283447, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  80%|████████  | 1601/2000 [28:54<07:13,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1600, loss: 30.265888127413664, num_train_sample: 22\n",
      "epoch: 1600, val_loss: 32.010183811187744, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  83%|████████▎ | 1651/2000 [29:48<06:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1650, loss: 30.337484273043547, num_train_sample: 22\n",
      "epoch: 1650, val_loss: 31.96937608718872, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  85%|████████▌ | 1701/2000 [30:42<05:23,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1700, loss: 30.39453272386031, num_train_sample: 22\n",
      "epoch: 1700, val_loss: 32.25892639160156, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  88%|████████▊ | 1751/2000 [31:35<04:31,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1750, loss: 30.089007897810504, num_train_sample: 22\n",
      "epoch: 1750, val_loss: 32.03260517120361, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  90%|█████████ | 1801/2000 [32:29<03:28,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1800, loss: 30.835477222095836, num_train_sample: 22\n",
      "epoch: 1800, val_loss: 32.13544702529907, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  93%|█████████▎| 1851/2000 [33:23<02:41,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1850, loss: 30.414102814414285, num_train_sample: 22\n",
      "epoch: 1850, val_loss: 32.09553861618042, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  95%|█████████▌| 1901/2000 [34:16<01:46,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1900, loss: 30.1575609553944, num_train_sample: 22\n",
      "epoch: 1900, val_loss: 31.99727725982666, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:  98%|█████████▊| 1951/2000 [35:09<00:52,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 1950, loss: 30.143220988186922, num_train_sample: 22\n",
      "epoch: 1950, val_loss: 32.05342483520508, num_valid_sample: 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch: 100%|██████████| 2000/2000 [36:01<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "MSE_loss_fn = nn.MSELoss()\n",
    "\n",
    "train_LOSS = []\n",
    "valid_LOSS = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"iterate epoch\"):\n",
    "    \n",
    "    losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    model.train()\n",
    "    for data, label in train_dataloader:\n",
    "        unmasked_data = data[0].float().to(device)\n",
    "        unmasked_idx = data[1].long().to(device)\n",
    "        masked_idx = data[2].long().to(device)\n",
    "        latent = data[3].float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        \n",
    "        pred = model(unmasked_data, unmasked_idx, masked_idx, latent)\n",
    "        \n",
    "        # only calculate mask loss\n",
    "        # label_mask = label[:, -len(masked_idx):]\n",
    "        # pred_mask = pred[:, -len(masked_idx):]\n",
    "        # loss = MSE_loss_fn(pred_mask, label_mask)\n",
    "\n",
    "        loss = MSE_loss_fn(pred, label)\n",
    "\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    train_LOSS.append(losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'total variables are {num_variables}: first {unmask_ratio} unmasked, latter {num_variables - unmask_ratio}')\n",
    "        print(f\"epoch: {epoch}, loss: {losses}, num_train_sample: {len(train_dataloader)}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, label in valid_dataloader:\n",
    "            unmasked_data = data[0].float().to(device)\n",
    "            unmasked_idx = data[1].long().to(device)\n",
    "            masked_idx = data[2].long().to(device)\n",
    "            latent = data[3].float().to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            pred = model(unmasked_data, unmasked_idx, masked_idx, latent)\n",
    "            \n",
    "            # only calculate mask loss\n",
    "            # label_mask = label[:, -len(masked_idx):]\n",
    "            # pred_mask = pred[:, -len(masked_idx):]\n",
    "            # loss = MSE_loss_fn(pred_mask, label_mask)\n",
    "            \n",
    "            loss = MSE_loss_fn(pred, label)\n",
    "\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "            \n",
    "    val_losses = np.mean(val_losses)\n",
    "    valid_LOSS.append(val_losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"epoch: {epoch}, val_loss: {val_losses}, num_valid_sample: {len(valid_dataloader)}\")\n",
    "        print()        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2098495/4028703919.py:6: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt .plot(range(len(train_LOSS)), train_LOSS, color = 'blue')\n",
    "plt.plot(range(len(valid_LOSS)), valid_LOSS, color = 'red')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unmasked_dat: (12,)\n",
      "unmasked_id: (12,)\n",
      "masked_id: (6,)\n",
      "label_: (18,)\n",
      "pred_: (18,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.059013</td>\n",
       "      <td>0.930044</td>\n",
       "      <td>2.044164</td>\n",
       "      <td>80.956963</td>\n",
       "      <td>77.003777</td>\n",
       "      <td>83.814072</td>\n",
       "      <td>66.218658</td>\n",
       "      <td>93.624268</td>\n",
       "      <td>21.848301</td>\n",
       "      <td>24.665663</td>\n",
       "      <td>7.751856</td>\n",
       "      <td>5.317892</td>\n",
       "      <td>0.301193</td>\n",
       "      <td>1.054168</td>\n",
       "      <td>0.033243</td>\n",
       "      <td>1.413223</td>\n",
       "      <td>70.216843</td>\n",
       "      <td>76.649887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.300003</td>\n",
       "      <td>76.290001</td>\n",
       "      <td>83.419998</td>\n",
       "      <td>65.230003</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.099998</td>\n",
       "      <td>50.220001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Grade  Internet_Access_at_Home  Family_Income_Level  Attendance (%)  \\\n",
       "0  2.059013                 0.930044             2.044164       80.956963   \n",
       "1  2.000000                 1.000000             2.000000       80.300003   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Projects_Score  \\\n",
       "0    77.003777        83.814072    66.218658       93.624268   \n",
       "1    76.290001        83.419998    65.230003       93.500000   \n",
       "\n",
       "   Study_Hours_per_Week        Age  Sleep_Hours_per_Night  \\\n",
       "0             21.848301  24.665663               7.751856   \n",
       "1             21.100000  24.000000               7.400000   \n",
       "\n",
       "   Stress_Level (1-10)    Gender  Department  Extracurricular_Activities  \\\n",
       "0             5.317892  0.301193    1.054168                    0.033243   \n",
       "1             5.000000  0.000000    1.000000                    1.000000   \n",
       "\n",
       "   Parent_Education_Level  Midterm_Score  Total_Score  \n",
       "0                1.413223      70.216843    76.649887  \n",
       "1                0.000000      45.099998    50.220001  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasked_dat = np.array(unmasked_data[0].detach().cpu())\n",
    "unmasked_id = np.array(unmasked_idx[0].detach().cpu(), dtype=int)\n",
    "masked_id = np.array(masked_idx[0].detach().cpu(), dtype=int)\n",
    "# latent_ = np.array(latent[0].detach().cpu(), dtype=int)\n",
    "label_ = np.array(label[0].detach().cpu())\n",
    "pred_ = np.array(pred[0].detach().cpu())\n",
    "\n",
    "unmask_cols = list(cols_name[unmasked_id])\n",
    "mask_cols = list(cols_name[masked_id])\n",
    "all_cols = unmask_cols + mask_cols\n",
    "\n",
    "res = pd.DataFrame([pred_, label_], columns = all_cols)\n",
    "\n",
    "print(f\"unmasked_dat: {unmasked_dat.shape}\")\n",
    "print(f\"unmasked_id: {unmasked_id.shape}\")\n",
    "print(f\"masked_id: {masked_id.shape}\")\n",
    "print(f\"label_: {label_.shape}\")\n",
    "print(f\"pred_: {pred_.shape}\")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
