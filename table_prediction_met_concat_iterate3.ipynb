{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"checkpoints/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Students_Grading_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually select Cols (attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Department</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>52.29</td>\n",
       "      <td>55.03</td>\n",
       "      <td>57.82</td>\n",
       "      <td>84.22</td>\n",
       "      <td>74.06</td>\n",
       "      <td>85.90</td>\n",
       "      <td>56.09</td>\n",
       "      <td>F</td>\n",
       "      <td>6.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>97.27</td>\n",
       "      <td>97.23</td>\n",
       "      <td>45.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.24</td>\n",
       "      <td>55.65</td>\n",
       "      <td>50.64</td>\n",
       "      <td>A</td>\n",
       "      <td>19.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Business</td>\n",
       "      <td>57.19</td>\n",
       "      <td>67.05</td>\n",
       "      <td>93.68</td>\n",
       "      <td>67.70</td>\n",
       "      <td>85.70</td>\n",
       "      <td>73.79</td>\n",
       "      <td>70.30</td>\n",
       "      <td>D</td>\n",
       "      <td>20.7</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Low</td>\n",
       "      <td>6</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>95.15</td>\n",
       "      <td>47.79</td>\n",
       "      <td>80.63</td>\n",
       "      <td>66.06</td>\n",
       "      <td>93.51</td>\n",
       "      <td>92.12</td>\n",
       "      <td>61.63</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>54.18</td>\n",
       "      <td>46.59</td>\n",
       "      <td>78.89</td>\n",
       "      <td>96.85</td>\n",
       "      <td>83.70</td>\n",
       "      <td>68.42</td>\n",
       "      <td>66.13</td>\n",
       "      <td>F</td>\n",
       "      <td>15.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>High</td>\n",
       "      <td>2</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.15</td>\n",
       "      <td>60.33</td>\n",
       "      <td>80.09</td>\n",
       "      <td>99.32</td>\n",
       "      <td>58.42</td>\n",
       "      <td>85.21</td>\n",
       "      <td>D</td>\n",
       "      <td>25.5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>High School</td>\n",
       "      <td>Low</td>\n",
       "      <td>10</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>Business</td>\n",
       "      <td>65.11</td>\n",
       "      <td>86.31</td>\n",
       "      <td>49.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.08</td>\n",
       "      <td>60.87</td>\n",
       "      <td>95.96</td>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>CS</td>\n",
       "      <td>87.54</td>\n",
       "      <td>63.55</td>\n",
       "      <td>64.21</td>\n",
       "      <td>94.28</td>\n",
       "      <td>50.19</td>\n",
       "      <td>82.65</td>\n",
       "      <td>54.25</td>\n",
       "      <td>A</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>High School</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>CS</td>\n",
       "      <td>92.56</td>\n",
       "      <td>79.79</td>\n",
       "      <td>94.28</td>\n",
       "      <td>81.20</td>\n",
       "      <td>61.18</td>\n",
       "      <td>94.29</td>\n",
       "      <td>55.84</td>\n",
       "      <td>A</td>\n",
       "      <td>16.1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>83.92</td>\n",
       "      <td>83.24</td>\n",
       "      <td>53.47</td>\n",
       "      <td>51.76</td>\n",
       "      <td>83.51</td>\n",
       "      <td>69.25</td>\n",
       "      <td>77.86</td>\n",
       "      <td>F</td>\n",
       "      <td>29.2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Low</td>\n",
       "      <td>2</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Gender  Age   Department  Attendance (%)  Midterm_Score  Final_Score  \\\n",
       "0     Female   22  Engineering           52.29          55.03        57.82   \n",
       "1       Male   18  Engineering           97.27          97.23        45.80   \n",
       "2       Male   24     Business           57.19          67.05        93.68   \n",
       "3     Female   24  Mathematics           95.15          47.79        80.63   \n",
       "4     Female   23           CS           54.18          46.59        78.89   \n",
       "...      ...  ...          ...             ...            ...          ...   \n",
       "4995    Male   19     Business             NaN          82.15        60.33   \n",
       "4996    Male   19     Business           65.11          86.31        49.80   \n",
       "4997  Female   24           CS           87.54          63.55        64.21   \n",
       "4998    Male   23           CS           92.56          79.79        94.28   \n",
       "4999  Female   21  Engineering           83.92          83.24        53.47   \n",
       "\n",
       "      Assignments_Avg  Quizzes_Avg  Projects_Score  Total_Score Grade  \\\n",
       "0               84.22        74.06           85.90        56.09     F   \n",
       "1                 NaN        94.24           55.65        50.64     A   \n",
       "2               67.70        85.70           73.79        70.30     D   \n",
       "3               66.06        93.51           92.12        61.63     A   \n",
       "4               96.85        83.70           68.42        66.13     F   \n",
       "...               ...          ...             ...          ...   ...   \n",
       "4995            80.09        99.32           58.42        85.21     D   \n",
       "4996              NaN        88.08           60.87        95.96     C   \n",
       "4997            94.28        50.19           82.65        54.25     A   \n",
       "4998            81.20        61.18           94.29        55.84     A   \n",
       "4999            51.76        83.51           69.25        77.86     F   \n",
       "\n",
       "      Study_Hours_per_Week Extracurricular_Activities Internet_Access_at_Home  \\\n",
       "0                      6.2                         No                     Yes   \n",
       "1                     19.0                         No                     Yes   \n",
       "2                     20.7                         No                     Yes   \n",
       "3                     24.8                        Yes                     Yes   \n",
       "4                     15.4                        Yes                     Yes   \n",
       "...                    ...                        ...                     ...   \n",
       "4995                  25.5                         No                     Yes   \n",
       "4996                   5.0                         No                     Yes   \n",
       "4997                  24.8                        Yes                      No   \n",
       "4998                  16.1                        Yes                     Yes   \n",
       "4999                  29.2                         No                     Yes   \n",
       "\n",
       "     Parent_Education_Level Family_Income_Level  Stress_Level (1-10)  \\\n",
       "0               High School              Medium                    5   \n",
       "1                       NaN              Medium                    4   \n",
       "2                  Master's                 Low                    6   \n",
       "3               High School                High                    3   \n",
       "4               High School                High                    2   \n",
       "...                     ...                 ...                  ...   \n",
       "4995            High School                 Low                   10   \n",
       "4996                    NaN              Medium                    4   \n",
       "4997            High School              Medium                    4   \n",
       "4998             Bachelor's                 Low                    1   \n",
       "4999                    PhD                 Low                    2   \n",
       "\n",
       "      Sleep_Hours_per_Night  \n",
       "0                       4.7  \n",
       "1                       9.0  \n",
       "2                       6.2  \n",
       "3                       6.7  \n",
       "4                       7.1  \n",
       "...                     ...  \n",
       "4995                    8.3  \n",
       "4996                    4.0  \n",
       "4997                    6.3  \n",
       "4998                    8.4  \n",
       "4999                    6.1  \n",
       "\n",
       "[5000 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unimportant_attribute = ['Student_ID', 'First_Name', 'Last_Name', 'Email', 'Participation_Score']\n",
    "\n",
    "filtered_df = df.drop(unimportant_attribute, axis=1)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sleep_Hours_per_Night', 'Study_Hours_per_Week', 'Age', 'Stress_Level (1-10)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "# numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Participation_Score', 'Projects_Score', 'Total_Score', 'Stress_Level (1-10)']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate rows with-Nan and without-Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row with Nan: (2419, 18)\n",
      "row without Nan: (2581, 18)\n"
     ]
    }
   ],
   "source": [
    "nan_rows = filtered_df.isna().any(axis=1)\n",
    "\n",
    "# Nan rows\n",
    "df_nan = filtered_df[nan_rows]\n",
    "print(f\"row with Nan: {df_nan.shape}\")\n",
    "\n",
    "# Complete rows\n",
    "df_complete = filtered_df[~nan_rows]\n",
    "print(f\"row without Nan: {df_complete.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train: (1806, 18)\n",
      "df_valid: (775, 18)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_valid, _, _ = train_test_split(df_complete, df_complete, test_size=0.3, random_state=0)\n",
    "\n",
    "df_train_id = [i for i in range(len(df_train))]\n",
    "df_valid_id = [i for i in range(len(df_valid))]\n",
    "\n",
    "print(f\"df_train: {df_train.shape}\")\n",
    "print(f\"df_valid: {df_valid.shape}\")\n",
    "\n",
    "# print(f\"df_train_id: {df_train_id}\")\n",
    "# print(f\"df_valid_id: {df_valid_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: \n",
    "1. category to numerical\n",
    "2. max-min norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_to_numerical(data):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(data)\n",
    "    num_data = le.transform(data)\n",
    "    \n",
    "    return num_data, le\n",
    "\n",
    "def max_min_norm_score(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 100\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "    \n",
    "def max_min_norm_scalar(data, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "    else:\n",
    "        data_max = 10\n",
    "        data_min = 0\n",
    "        \n",
    "    norm_data = (data - data_min) / (data_max - data_min)    \n",
    "    \n",
    "    if process_type == 'train':\n",
    "        return norm_data, data_max, data_min\n",
    "    else:\n",
    "        return norm_data\n",
    "\n",
    "    \n",
    "def preprocessing(df, train_params = None, process_type = 'train'):\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "    if process_type == 'train':\n",
    "        train_params = {}\n",
    "        category_var_len = {}\n",
    "\n",
    "    # Category \n",
    "    for cat_name in category_vars:\n",
    "        cat_var = df[cat_name]\n",
    "        if process_type == 'train':\n",
    "            cat_var, le = category_to_numerical(cat_var)\n",
    "            train_params[f'{cat_name}_le'] = le\n",
    "            category_var_len[f'{cat_name}'] = len(np.unique(cat_var))\n",
    "        else:\n",
    "            cat_var = train_params[f'{cat_name}_le'].transform(cat_var)\n",
    "        new_df[f'{cat_name}'] = cat_var\n",
    "    \n",
    "    # Numerical score\n",
    "    for num_name in numerical_score_vars:\n",
    "        num_var = df[num_name]\n",
    "        if process_type == 'train':\n",
    "            num_var, data_max, data_min = max_min_norm_score(num_var, process_type = 'train')\n",
    "            train_params[num_name] = [data_max, data_min]\n",
    "        else:\n",
    "            num_var = max_min_norm_score(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "    \n",
    "    # Numerical scalar\n",
    "    for num_name in numerical_scalar_vars:\n",
    "        num_var = df[num_name]\n",
    "        num_var = np.log(num_var)\n",
    "        if process_type == 'train':\n",
    "            num_var, data_max, data_min = max_min_norm_scalar(num_var, process_type = 'train')\n",
    "            train_params[num_name] = [data_max, data_min]\n",
    "        else:\n",
    "            num_var = max_min_norm_scalar(num_var, train_params, process_type = 'valid')\n",
    "        new_df[num_name] = num_var.values\n",
    "        \n",
    "        \n",
    "    if process_type == 'train':\n",
    "        return new_df, train_params, category_var_len\n",
    "    else:\n",
    "        return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_var_len: {'Gender': 2, 'Department': 4, 'Grade': 5, 'Extracurricular_Activities': 2, 'Internet_Access_at_Home': 2, 'Parent_Education_Level': 4, 'Family_Income_Level': 3}\n",
      "processed_df_train: (1806, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>0.4255</td>\n",
       "      <td>0.5045</td>\n",
       "      <td>0.5528</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>0.7426</td>\n",
       "      <td>0.212823</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>0.317805</td>\n",
       "      <td>0.138629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5562</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.4543</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>0.9215</td>\n",
       "      <td>0.6371</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.193152</td>\n",
       "      <td>0.177495</td>\n",
       "      <td>0.313549</td>\n",
       "      <td>0.069315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6309</td>\n",
       "      <td>0.6057</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.5671</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>0.158924</td>\n",
       "      <td>0.293916</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.194591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>0.4550</td>\n",
       "      <td>0.5771</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.8337</td>\n",
       "      <td>0.210413</td>\n",
       "      <td>0.282138</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.230259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9590</td>\n",
       "      <td>0.8459</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.5204</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.6554</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>0.218605</td>\n",
       "      <td>0.184055</td>\n",
       "      <td>0.304452</td>\n",
       "      <td>0.179176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           1      1                           1   \n",
       "1       1           3      2                           0   \n",
       "2       1           1      4                           0   \n",
       "3       1           2      2                           1   \n",
       "4       0           2      1                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       0                    1   \n",
       "1                        1                       3                    2   \n",
       "2                        1                       1                    1   \n",
       "3                        1                       1                    2   \n",
       "4                        1                       1                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0          0.8989         0.4255       0.5045           0.5528       0.7634   \n",
       "1          0.5562         0.8190       0.4543           0.5380       0.9215   \n",
       "2          0.6309         0.6057       0.5680           0.5342       0.8288   \n",
       "3          0.6077         0.9869       0.4550           0.5771       0.5339   \n",
       "4          0.9590         0.8459       0.6858           0.5204       0.6389   \n",
       "\n",
       "   Projects_Score  Total_Score  Sleep_Hours_per_Night  Study_Hours_per_Week  \\\n",
       "0          0.5783       0.7426               0.212823              0.332504   \n",
       "1          0.6371       0.8995               0.193152              0.177495   \n",
       "2          0.5671       0.5943               0.158924              0.293916   \n",
       "3          0.5516       0.8337               0.210413              0.282138   \n",
       "4          0.6554       0.8854               0.218605              0.184055   \n",
       "\n",
       "        Age  Stress_Level (1-10)  \n",
       "0  0.317805             0.138629  \n",
       "1  0.313549             0.069315  \n",
       "2  0.294444             0.194591  \n",
       "3  0.294444             0.230259  \n",
       "4  0.304452             0.179176  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_train, train_params, category_var_len = preprocessing(df_train, process_type = 'train')\n",
    "# train_params\n",
    "print(f\"category_var_len: {category_var_len}\")\n",
    "print(f\"processed_df_train: {processed_df_train.shape}\")\n",
    "\n",
    "cols_name = processed_df_train.columns\n",
    "processed_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_df_valid: (775, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.5002</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.214007</td>\n",
       "      <td>0.283908</td>\n",
       "      <td>0.294444</td>\n",
       "      <td>0.207944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.6142</td>\n",
       "      <td>0.5457</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.5397</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.141099</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.289037</td>\n",
       "      <td>0.207944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.7315</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>0.5537</td>\n",
       "      <td>0.5564</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.5429</td>\n",
       "      <td>0.193152</td>\n",
       "      <td>0.294969</td>\n",
       "      <td>0.317805</td>\n",
       "      <td>0.219722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5228</td>\n",
       "      <td>0.8212</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.8334</td>\n",
       "      <td>0.6564</td>\n",
       "      <td>0.185630</td>\n",
       "      <td>0.319458</td>\n",
       "      <td>0.304452</td>\n",
       "      <td>0.194591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>0.8329</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.6557</td>\n",
       "      <td>0.200148</td>\n",
       "      <td>0.236085</td>\n",
       "      <td>0.313549</td>\n",
       "      <td>0.109861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Grade  Extracurricular_Activities  \\\n",
       "0       1           3      2                           0   \n",
       "1       1           1      1                           1   \n",
       "2       1           3      2                           0   \n",
       "3       1           1      3                           1   \n",
       "4       1           2      0                           0   \n",
       "\n",
       "   Internet_Access_at_Home  Parent_Education_Level  Family_Income_Level  \\\n",
       "0                        1                       2                    1   \n",
       "1                        1                       2                    1   \n",
       "2                        1                       3                    0   \n",
       "3                        1                       2                    1   \n",
       "4                        1                       0                    2   \n",
       "\n",
       "   Attendance (%)  Midterm_Score  Final_Score  Assignments_Avg  Quizzes_Avg  \\\n",
       "0          0.5154         0.6404       0.5002           0.8728       0.9699   \n",
       "1          0.9970         0.9376       0.6142           0.5457       0.7576   \n",
       "2          0.6151         0.7315       0.4190           0.5537       0.5564   \n",
       "3          0.5228         0.8212       0.9962           0.5518       0.5023   \n",
       "4          0.9474         0.5340       0.6216           0.8329       0.7903   \n",
       "\n",
       "   Projects_Score  Total_Score  Sleep_Hours_per_Night  Study_Hours_per_Week  \\\n",
       "0          0.8258       0.8888               0.214007              0.283908   \n",
       "1          0.5397       0.6468               0.141099              0.194591   \n",
       "2          0.7862       0.5429               0.193152              0.294969   \n",
       "3          0.8334       0.6564               0.185630              0.319458   \n",
       "4          0.6250       0.6557               0.200148              0.236085   \n",
       "\n",
       "        Age  Stress_Level (1-10)  \n",
       "0  0.294444             0.207944  \n",
       "1  0.289037             0.207944  \n",
       "2  0.317805             0.219722  \n",
       "3  0.304452             0.194591  \n",
       "4  0.313549             0.109861  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df_valid = preprocessing(df_valid, train_params, process_type = 'valid')\n",
    "print(f\"processed_df_valid: {processed_df_valid.shape}\")\n",
    "processed_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "# MASK_RATIO = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_helper(data, MASK_RATIO, seed = 42):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    rows, cols = data.shape\n",
    "    \n",
    "    # define mask/unmask ratio\n",
    "    unmask_ratio = ((100 - MASK_RATIO) * cols) // 100\n",
    "    mask_ratio = cols - unmask_ratio\n",
    "\n",
    "    # create random index\n",
    "    # shuff_idx = np.array([np.random.permutation(cols) for _ in range(rows)])\n",
    "    shuff_idx = np.random.permutation(cols).reshape(1, cols)\n",
    "    shuff_idx = np.repeat(shuff_idx, rows, axis = 0)\n",
    "\n",
    "    # define mask/unmask idx\n",
    "    mask_idx = shuff_idx[:, :mask_ratio]\n",
    "    unmask_idx = shuff_idx[:, mask_ratio:]\n",
    "    \n",
    "    mask_idx.sort(axis=1)\n",
    "    unmask_idx.sort(axis=1)\n",
    "    \n",
    "    # create new_data (contain unmask cols, but remove mask cols)\n",
    "    new_data = np.zeros((rows, unmask_ratio))\n",
    "    for i in range(rows):\n",
    "        new_data[i] = data[i][unmask_idx[i]]\n",
    "        \n",
    "    return new_data, unmask_idx, mask_idx, unmask_ratio\n",
    "\n",
    "def masking_fn(data, mask_ratio, seed):\n",
    "    sample_size = len(data)\n",
    "\n",
    "    new_data, unmask_idx, mask_idx, unmask_ratio = masking_helper(data, mask_ratio, seed)\n",
    "        \n",
    "    X = [[],[],[],[]]\n",
    "    Y = []\n",
    "\n",
    "    for i in range(sample_size):\n",
    "        X[0].append(new_data[i]) # unmask data\n",
    "        X[1].append(unmask_idx[i]) # unmask id\n",
    "        X[2].append(mask_idx[i]) # mask id\n",
    "        X[3].append(np.ones(unmask_ratio)) # len = unmask, serve as random noisee in VAE\n",
    "        Y.append(data[i][list(unmask_idx[i])+list(mask_idx[i])]) # label (unmask + mask)\n",
    "\n",
    "    X[0] = torch.tensor(np.array(X[0])) # unmask data\n",
    "    X[1] = torch.tensor(np.array(X[1])) # unmask id\n",
    "    X[2] = torch.tensor(np.array(X[2])) # mask id\n",
    "    X[3] = torch.tensor(np.array(X[3])) # latent space\n",
    "    \n",
    "    Y = torch.tensor(np.array(Y))\n",
    "    \n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(data_wtih_type):\n",
    "\n",
    "    # data\n",
    "    data = [dat[0] for dat in data_wtih_type]\n",
    "    data = np.array(data)\n",
    "    \n",
    "    # data type: training/valid\n",
    "    data_type = data_wtih_type[0][1]\n",
    "\n",
    "    if data_type == 'training':\n",
    "        seed = np.random.randint(10, size=1)\n",
    "        mask_ratio = np.random.randint(low = 3, high = 3 + 1, size=1) * 10\n",
    "        mask_ratio = mask_ratio[0]\n",
    "\n",
    "    else:\n",
    "        seed = 42\n",
    "        mask_ratio = 30\n",
    "        \n",
    "    data, label = masking_fn(data, mask_ratio, seed)\n",
    "\n",
    "    return data, label, mask_ratio\n",
    "\n",
    "class TableDataset(Dataset):\n",
    "    def __init__(self, data, data_type = 'training'):\n",
    "        self.data = data\n",
    "        self.data_type = data_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, id):\n",
    "        dat = self.data.iloc[id, :]\n",
    "        dat = np.array(dat)\n",
    "        return dat, self.data_type\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "augmented_processed_df_train = [processed_df_train] * 5\n",
    "augmented_processed_df_train = pd.concat(augmented_processed_df_train, axis = 0)\n",
    "\n",
    "train_dataset = TableDataset(augmented_processed_df_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers = 4, shuffle=False, collate_fn = collate_fn_train)\n",
    "\n",
    "\n",
    "valid_dataset = TableDataset(processed_df_valid, data_type = 'valid')\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, num_workers = 4, shuffle=False, collate_fn = collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, num_head, encoder_emb_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.num_head = num_head\n",
    "        self.encoder_emb_dim = encoder_emb_dim\n",
    "\n",
    "        # up_emb_size * 3 for qkv\n",
    "        self.qkv_fn = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim * 3, bias=False)\n",
    "        self.proj_qkv = nn.Linear(self.encoder_emb_dim, self.encoder_emb_dim, bias = False)\n",
    "                \n",
    "        # other\n",
    "        self.att_dropout = nn.Dropout(dropout)\n",
    "    \n",
    "            \n",
    "    def softclamp(self, t, value = 50.):\n",
    "        return (t / value).tanh() * value\n",
    "        \n",
    "        \n",
    "    def forward(self, x, iterative):\n",
    "\n",
    "        batch_size, num_vars, _ = x.shape\n",
    "\n",
    "        # qkv: up_emb_size * 3\n",
    "        x = self.qkv_fn(x) \n",
    "        q, k, v = x.split(self.encoder_emb_dim, dim = 2) \n",
    "        \n",
    "        # split head: each shape = [batch_size, num_head, num_vars(seq_len), head_size = 8]\n",
    "        q = q.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        k = k.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        v = v.view(batch_size, num_vars, self.num_head, self.encoder_emb_dim // self.num_head).transpose(1, 2)\n",
    "        \n",
    "        # attention matrix calculation: [batch_size, num_head, num_vars(seq_len), num_vars]\n",
    "        att = (q @ k.transpose(-2,-1)) * (1 / torch.sqrt(torch.ones([1]).to(device) * k.size(-1)))\n",
    "        \n",
    "        # masking the att from unmask to mask (Q_unmask to K_mask), \n",
    "        # because mask is basically noise, it's meaningless to ask informative vector (Q_unmask) to refer to noise vector (K_mask)\n",
    "        '''\n",
    "        it's not causal mask\n",
    "        it looks like:\n",
    "                unmask, unmaskm, mask  \n",
    "        unmask  [1,      1,      0] \n",
    "        unmask  [1,      1,      0] \n",
    "        mask    [1,      1,      1] \n",
    "        '''\n",
    "        if iterative:\n",
    "            mask_id = num_vars - 1\n",
    "            att_mask = torch.ones_like(att)\n",
    "            att_mask[:, :, :mask_id, -1] = 0\n",
    "            att = att.masked_fill(att_mask == 0, float('-inf')) \n",
    "\n",
    "        # att = self.softclamp(att, 15)\n",
    "\n",
    "        att = F.softmax(att, dim = -1)\n",
    "        att = self.att_dropout(att)\n",
    "        \n",
    "        # att matrix * V: [batch_size, num_head, num_vars(seq_len), head_size]\n",
    "        out = att @ v\n",
    "        out = out.transpose(1,2).contiguous().view(batch_size, num_vars, self.encoder_emb_dim)\n",
    "        out = self.proj_qkv(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, transformer_emb_size, dropout):\n",
    "        super().__init__()\n",
    "        self.up    = nn.Linear(transformer_emb_size, transformer_emb_size * 3)\n",
    "        self.relu  = nn.ReLU()\n",
    "        self.down  = nn.Linear(transformer_emb_size * 3, transformer_emb_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.down(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, num_head, dropout):\n",
    "        super(Block, self).__init__()\n",
    "        self.ln_head = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.head = Head(num_head, encoder_emb_dim, dropout)\n",
    "        self.dropout_head = nn.Dropout(dropout)\n",
    "\n",
    "        self.ln_mlp = nn.LayerNorm(encoder_emb_dim)\n",
    "        self.mlp = MLP(encoder_emb_dim, dropout)\n",
    "        self.dropout_mlp = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, iterative):\n",
    "        \n",
    "        # att \n",
    "        ori_x = x \n",
    "        x = self.head(x, iterative)\n",
    "        x = self.dropout_head(x)\n",
    "        x = self.ln_head(ori_x + x)\n",
    "        \n",
    "        # linear \n",
    "        ori_x = x \n",
    "        x = self.mlp(x)\n",
    "        x = self.dropout_mlp(x)\n",
    "        x = self.ln_mlp(ori_x + x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder_emb_dim, layers, num_head, dropout):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.ModuleList(Block(encoder_emb_dim, num_head, dropout) for _ in range(layers))\n",
    "        \n",
    "    def forward(self, x, iterative = False):\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, iterative)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sleep_Hours_per_Night', 'Study_Hours_per_Week', 'Age', 'Stress_Level (1-10)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Embed(nn.Module):\n",
    "    def __init__(self, cols_name, category_vars, feature_emb_size, num_variables, position_emb_dim, category_var_len):\n",
    "        super().__init__()\n",
    "        self.cols_name = cols_name\n",
    "        self.category_vars = category_vars\n",
    "        self.feature_emb_size = feature_emb_size\n",
    "        self.category_var_len = category_var_len\n",
    "        self.hidden_size = feature_emb_size + position_emb_dim\n",
    "\n",
    "        # Category feature embedding\n",
    "        self.cat_encoders = {\n",
    "            'Gender': nn.Embedding(category_var_len['Gender'] + 1, feature_emb_size),\n",
    "            'Department': nn.Embedding(category_var_len['Department'] + 1, feature_emb_size),\n",
    "            'Grade': nn.Embedding(category_var_len['Grade'] + 1, feature_emb_size),\n",
    "            'Extracurricular_Activities': nn.Embedding(category_var_len['Extracurricular_Activities'] + 1, feature_emb_size),\n",
    "            'Internet_Access_at_Home': nn.Embedding(category_var_len['Internet_Access_at_Home'] + 1, feature_emb_size),\n",
    "            'Parent_Education_Level': nn.Embedding(category_var_len['Parent_Education_Level'] + 1, feature_emb_size),\n",
    "            'Family_Income_Level': nn.Embedding(category_var_len['Family_Income_Level'] + 1, feature_emb_size),\n",
    "        }\n",
    "        \n",
    "        self.cat_decoder1 = nn.Linear(self.hidden_size, self.hidden_size * 2, bias = False)\n",
    "        self.cat_decoder2 = nn.Linear(self.hidden_size * 2, self.hidden_size * 4, bias = False)\n",
    "        self.cat_decoder3 = nn.Linear(self.hidden_size * 4, self.hidden_size * 2, bias = False)\n",
    "        self.cat_decoder4 = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = False)\n",
    "        self.cat_decoder5 = nn.Linear(self.hidden_size, feature_emb_size, bias = False)\n",
    "        \n",
    "        self.cat_decoders = {\n",
    "        # self.cat_decoders_proj_pred = {\n",
    "            'Gender': nn.Linear(self.hidden_size, category_var_len['Gender'] + 1, bias=False),\n",
    "            'Department': nn.Linear(self.hidden_size, category_var_len['Department'] + 1, bias=False),\n",
    "            'Grade': nn.Linear(self.hidden_size, category_var_len['Grade'] + 1, bias=False),\n",
    "            'Extracurricular_Activities': nn.Linear(self.hidden_size, category_var_len['Extracurricular_Activities'] + 1, bias=False),\n",
    "            'Internet_Access_at_Home': nn.Linear(self.hidden_size, category_var_len['Internet_Access_at_Home'] + 1, bias=False),\n",
    "            'Parent_Education_Level': nn.Linear(self.hidden_size, category_var_len['Parent_Education_Level'] + 1, bias=False),\n",
    "            'Family_Income_Level': nn.Linear(self.hidden_size, category_var_len['Family_Income_Level'] + 1, bias=False),\n",
    "        }\n",
    "        \n",
    "        # self.cat_encoders['Gender'].weight = self.cat_decoders_proj_pred['Gender'].weight        \n",
    "        # self.cat_encoders['Department'].weight = self.cat_decoders_proj_pred['Department'].weight        \n",
    "        # self.cat_encoders['Grade'].weight = self.cat_decoders_proj_pred['Grade'].weight        \n",
    "        # self.cat_encoders['Extracurricular_Activities'].weight = self.cat_decoders_proj_pred['Extracurricular_Activities'].weight        \n",
    "        # self.cat_encoders['Internet_Access_at_Home'].weight = self.cat_decoders_proj_pred['Internet_Access_at_Home'].weight        \n",
    "        # self.cat_encoders['Parent_Education_Level'].weight = self.cat_decoders_proj_pred['Parent_Education_Level'].weight        \n",
    "        # self.cat_encoders['Family_Income_Level'].weight = self.cat_decoders_proj_pred['Family_Income_Level'].weight        \n",
    "\n",
    "        # numerical decoder\n",
    "        self.numerical_decoder1 = nn.Linear(self.hidden_size, self.hidden_size * 2, bias = False)\n",
    "        self.numerical_decoder2 = nn.Linear(self.hidden_size * 2, self.hidden_size * 4, bias = False)\n",
    "        self.numerical_decoder3 = nn.Linear(self.hidden_size * 4, self.hidden_size * 2, bias = False)\n",
    "        self.numerical_decoder4 = nn.Linear(self.hidden_size * 2, self.hidden_size, bias = False)\n",
    "        self.numerical_decoder5 = nn.Linear(self.hidden_size, 1, bias = False)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.cols_id_name = {}\n",
    "        count = 0\n",
    "        for col in self.cols_name:\n",
    "            self.cols_id_name[count] = col\n",
    "            count += 1\n",
    "            \n",
    "        # positional embedding \n",
    "        self.position_emb_dim = position_emb_dim\n",
    "        self.pos_emb = nn.Embedding(num_variables, position_emb_dim)            \n",
    "\n",
    "    def encode(self, unmasked_data, unmasked_idx, masked_idx):\n",
    "        \n",
    "        batch_size, num_unmask_cols = unmasked_data.shape\n",
    "        _, num_mask_cols = masked_idx.shape\n",
    "        device = unmasked_data.device\n",
    "        \n",
    "        # position info\n",
    "        unmasked_pos_info = self.pos_emb(unmasked_idx.long()).float()\n",
    "        masked_pos_info = self.pos_emb(masked_idx.long()).float()        \n",
    "        \n",
    "        ''' Feature Encoding for Unmask '''\n",
    "        \n",
    "        # iterate every col in unmask\n",
    "        # for category, do nn.Embedding\n",
    "        # for numerical, repeat feature_emb_size times\n",
    "        unmasked_emb = []\n",
    "        for c in range(num_unmask_cols):\n",
    "            unmask_attribute_value = unmasked_data[:, c]\n",
    "            \n",
    "            # make sure unmask_attribute_id is unique along one col dimension\n",
    "            # use the unique id to see the choosen attribute is categorial or numerical\n",
    "            unmask_attribute_id = unmasked_idx[:, c]\n",
    "            assert len(torch.unique(unmask_attribute_id)) == 1, \"unmask_attribute_id in one small batch has to be the same\"\n",
    "            unmask_attribute_id = torch.unique(unmask_attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[unmask_attribute_id] in self.category_vars:\n",
    "                # print(f\"col_name: {self.cols_id_name[unmask_attribute_id]}\")\n",
    "                encoder = self.cat_encoders[self.cols_id_name[unmask_attribute_id]].to(device)\n",
    "                unmask_attribute_emb = encoder(unmask_attribute_value.long()).float()\n",
    "                unmasked_emb.append(unmask_attribute_emb)\n",
    "            # this col is numerical\n",
    "            else:\n",
    "                unmask_attribute_value = torch.unsqueeze(unmask_attribute_value, dim = 1)\n",
    "                unmask_attribute_emb = unmask_attribute_value.repeat(1, self.feature_emb_size)\n",
    "                unmasked_emb.append(unmask_attribute_emb)\n",
    "\n",
    "        unmasked_emb = torch.stack(unmasked_emb, dim = 1)\n",
    "        \n",
    "        ''' Positional Encoding for Unmask '''\n",
    "        unmasked_emb = torch.cat([unmasked_emb, unmasked_pos_info], dim = 2) # (batch_size, num_unmask_vars, feature_emb_size + pos_emb_size)\n",
    "\n",
    "        \n",
    "        ''' Feature Encoding for Mask '''\n",
    "        # create noise for categorial and numerical seperately\n",
    "        masked_emb = []\n",
    "        for c in range(num_mask_cols):\n",
    "            mask_attribute_id = masked_idx[:, c]\n",
    "            assert len(torch.unique(mask_attribute_id)) == 1, \"mask_attribute_id in one small batch has to be the same\"\n",
    "            mask_attribute_id = torch.unique(mask_attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[mask_attribute_id] in self.category_vars:\n",
    "                # get col name\n",
    "                col_name = self.cols_id_name[mask_attribute_id]\n",
    "                encoder = self.cat_encoders[col_name].to(device)\n",
    "                \n",
    "                # create categorial mask id\n",
    "                category_mask_id = self.category_var_len[col_name]\n",
    "                categorial_latent = torch.ones(batch_size).to(device) * category_mask_id\n",
    "\n",
    "                categorial_emb = encoder(categorial_latent.long()).float()\n",
    "                masked_emb.append(categorial_emb)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:\n",
    "                # create rand(0-1) as numerical latent\n",
    "                numerical_latent = torch.ones(batch_size).to(device) * torch.rand(1).to(device)\n",
    "                numerical_latent = torch.unsqueeze(numerical_latent, dim = 1)\n",
    "                numerical_emb = numerical_latent.repeat(1, self.feature_emb_size)\n",
    "                masked_emb.append(numerical_emb)\n",
    "\n",
    "        masked_emb = torch.stack(masked_emb, dim = 1)\n",
    "        \n",
    "        ''' Positional Encoding for Mask '''\n",
    "        masked_emb = torch.cat([masked_emb, masked_pos_info], dim = 2) # (batch_size, num_mask_vars, feature_emb_size + pos_emb_size)\n",
    "\n",
    "        return unmasked_emb, masked_emb\n",
    "    \n",
    "    def decode(self, all_emb, unmask_mask_id):\n",
    "\n",
    "        batch_size, num_cols, hidden_size = all_emb.shape\n",
    "        device = all_emb.device\n",
    "        \n",
    "        ''' decode for unmask and mask '''\n",
    "        categorial_preds = []\n",
    "        numerical_preds = []\n",
    "        \n",
    "        categorial_col_name = []\n",
    "        numerical_col_name = []\n",
    "        \n",
    "        for c in range(num_cols):\n",
    "            # attribute value\n",
    "            attribute_value = all_emb[:, c, :]\n",
    "\n",
    "            # attribute id\n",
    "            attribute_id = unmask_mask_id[:, c]\n",
    "            assert len(torch.unique(attribute_id)) == 1, \"attribute_id in one small batch has to be the same\"\n",
    "            attribute_id = torch.unique(attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[attribute_id] in self.category_vars:\n",
    "                col_name = self.cols_id_name[attribute_id]\n",
    "                decoder = self.cat_decoders[col_name].to(device)\n",
    "                cat_pred = decoder(attribute_value)\n",
    "\n",
    "                categorial_preds.append(cat_pred)\n",
    "                categorial_col_name.append(col_name)\n",
    "                \n",
    "                # col_name = self.cols_id_name[attribute_id]\n",
    "                # categorial_preds.append(attribute_value)\n",
    "                # categorial_col_name.append(col_name)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:                \n",
    "                col_name = self.cols_id_name[attribute_id]\n",
    "                numerical_col_name.append(col_name)\n",
    "                \n",
    "                numerical_preds.append(attribute_value)\n",
    "\n",
    "        # # decode for categorial\n",
    "        # categorial_preds = torch.stack(categorial_preds, dim = 1)\n",
    "        \n",
    "        # ori_categorial_preds = categorial_preds\n",
    "        \n",
    "        # categorial_preds = self.cat_decoder1(categorial_preds).to(device)\n",
    "        # categorial_preds = self.relu(categorial_preds)\n",
    "        \n",
    "        # categorial_preds = self.cat_decoder2(categorial_preds).to(device)\n",
    "        # categorial_preds = self.relu(categorial_preds)\n",
    "        \n",
    "        # categorial_preds = self.cat_decoder3(categorial_preds).to(device)\n",
    "        # categorial_preds = self.relu(categorial_preds)\n",
    "        \n",
    "        # categorial_preds = self.cat_decoder4(categorial_preds).to(device)\n",
    "        # categorial_preds = self.relu(categorial_preds)\n",
    "        \n",
    "        # # residual connection\n",
    "        # categorial_preds = categorial_preds + ori_categorial_preds\n",
    "        # categorial_preds = self.cat_decoder5(categorial_preds).to(device)\n",
    "\n",
    "        # categorial_projs = []\n",
    "        # for i in range(len(self.category_vars)):\n",
    "        #     decoder = self.cat_decoders_proj_pred[categorial_col_name[i]].to(device)\n",
    "        #     pred = decoder(categorial_preds[:, i, :])\n",
    "        #     categorial_projs.append(pred)\n",
    "        # categorial_preds = categorial_projs\n",
    "\n",
    "        # decode for numerical\n",
    "        numerical_preds = torch.stack(numerical_preds, dim = 1)\n",
    "        \n",
    "        ori_numerical_preds = numerical_preds\n",
    "        \n",
    "        numerical_preds = self.numerical_decoder1(numerical_preds).to(device)\n",
    "        numerical_preds = self.relu(numerical_preds)\n",
    "        \n",
    "        numerical_preds = self.numerical_decoder2(numerical_preds).to(device)\n",
    "        numerical_preds = self.relu(numerical_preds)\n",
    "        \n",
    "        numerical_preds = self.numerical_decoder3(numerical_preds).to(device)\n",
    "        numerical_preds = self.relu(numerical_preds)\n",
    "        \n",
    "        numerical_preds = self.numerical_decoder4(numerical_preds).to(device)\n",
    "        numerical_preds = self.relu(numerical_preds)\n",
    "        \n",
    "        # residual connection\n",
    "        numerical_preds = numerical_preds + ori_numerical_preds\n",
    "        numerical_preds = self.numerical_decoder5(numerical_preds).to(device)\n",
    "\n",
    "        numerical_preds = torch.squeeze(numerical_preds)\n",
    "        \n",
    "        return categorial_preds, numerical_preds, categorial_col_name, numerical_col_name\n",
    "    \n",
    "    \n",
    "    def reorder_label_fn(self, label, unmask_mask_id):\n",
    "        \n",
    "        batch_size, num_cols = label.shape\n",
    "        device = label.device\n",
    "        \n",
    "        ''' reorder for unmask and mask '''\n",
    "        categorial_labels = []\n",
    "        numerical_labels = []\n",
    "        \n",
    "        for c in range(num_cols):\n",
    "            # attribute value\n",
    "            attribute_value = label[:, c]\n",
    "\n",
    "            # attribute id\n",
    "            attribute_id = unmask_mask_id[:, c]\n",
    "            assert len(torch.unique(attribute_id)) == 1, \"attribute_id in one small batch has to be the same\"\n",
    "            attribute_id = torch.unique(attribute_id).item()\n",
    "\n",
    "            # this col is categorial \n",
    "            if self.cols_id_name[attribute_id] in self.category_vars:\n",
    "                categorial_labels.append(attribute_value)\n",
    "                \n",
    "            # this col is numerical\n",
    "            else:\n",
    "                numerical_labels.append(attribute_value)\n",
    "              \n",
    "        numerical_labels = torch.stack(numerical_labels, dim = 1)\n",
    "\n",
    "        return categorial_labels, numerical_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tableMET(nn.Module):\n",
    "    def __init__(self, position_emb_dim, layers_encode, layers_decode, layers_iterative_transformer, \\\n",
    "                 num_head, num_variables, cols_name, category_vars, feature_emb_size, category_var_len, dropout):\n",
    "        super().__init__()\n",
    "        self.num_variables = num_variables\n",
    "\n",
    "        # feature embedding\n",
    "        self.feature_emb_fn = Feature_Embed(cols_name, category_vars, feature_emb_size, num_variables, position_emb_dim, category_var_len)\n",
    "\n",
    "        # encoder and decoder\n",
    "        self.transformer_encode = Transformer(position_emb_dim + feature_emb_size, layers_encode, num_head, dropout)\n",
    "        self.transformer_decode = Transformer(position_emb_dim + feature_emb_size, layers_decode, num_head, dropout)\n",
    "        \n",
    "        # iterative transformer decoding\n",
    "        # self.iterative_transformer_decode = nn.ModuleList(Transformer(position_emb_dim + feature_emb_size, layers_iterative_transformer, num_head, dropout) for _ in range(self.mask_ratio))\n",
    "        self.iterative_transformer_decode = Transformer(position_emb_dim + feature_emb_size, layers_iterative_transformer, num_head, dropout)\n",
    "        \n",
    "    def forward(self, unmasked_data, unmasked_idx, masked_idx, label, mask_ratio):\n",
    "        self.unmask_ratio = ((100 - mask_ratio) * self.num_variables) // 100\n",
    "        self.mask_ratio = self.num_variables - ((100 - mask_ratio) * self.num_variables) // 100\n",
    "    \n",
    "        ''' feature & position encoding for Unmask and Mask '''\n",
    "        # unmask_emb: [batch_size, num_unmask = 12, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 12, 64])\n",
    "        # mask_emb: [batch_size, num_mask = 6, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 6, 64])\n",
    "        unmask_emb, mask_emb = self.feature_emb_fn.encode(unmasked_data, unmasked_idx, masked_idx)\n",
    "        \n",
    "        # transformer (encoder) only for unmasked part\n",
    "        # unmask_emb: [batch_size, num_unmask = 12, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 12, 64])\n",
    "        ori_unmask_emb = unmask_emb\n",
    "        unmask_emb = self.transformer_encode(unmask_emb)\n",
    "        unmask_emb = unmask_emb + ori_unmask_emb\n",
    "        \n",
    "        # iterative transformer decoding\n",
    "        mask_emb_iter = []\n",
    "        for mask_id in range(self.mask_ratio):\n",
    "            maske_e = torch.unsqueeze(mask_emb[:, mask_id, :], dim = 1)\n",
    "            unmask_mask_emb = torch.cat([unmask_emb, maske_e], dim = 1)\n",
    "            unmask_mask_emb = self.iterative_transformer_decode(unmask_mask_emb, iterative = True)\n",
    "            mask_emb_ = torch.unsqueeze(unmask_mask_emb[:, -1, :], dim = 1)\n",
    "            mask_emb_iter.append(mask_emb_)\n",
    "\n",
    "        mask_emb_iter = torch.cat(mask_emb_iter, dim = 1)\n",
    "    \n",
    "        # concat unmask_emb and mask_emb\n",
    "        all_emb = torch.cat([unmask_emb, mask_emb_iter], dim = 1)\n",
    "        \n",
    "        # transformer (decoder) for both unmasked and masked\n",
    "        # all_emb: [batch_size, num_vars = 18, hidden_size(position_emb_dim + feature_emb_size)]: ([4, 18, 64])\n",
    "        ori_all_emb = all_emb\n",
    "        all_emb = self.transformer_decode(all_emb)\n",
    "        all_emb = all_emb + ori_all_emb\n",
    "        \n",
    "        ''' feature & position decoding for Unmask and Mask '''\n",
    "        unmask_mask_id = torch.cat([unmasked_idx, masked_idx], dim = 1)\n",
    "        categorial_preds, numerical_preds, categorial_col_name, numerical_col_name = self.feature_emb_fn.decode(all_emb, unmask_mask_id)\n",
    "\n",
    "        ''' reorder label: make label' variable order align as pred '''\n",
    "        categorial_labels, numerical_labels = self.feature_emb_fn.reorder_label_fn(label, unmask_mask_id)\n",
    "            \n",
    "\n",
    "        return categorial_preds, numerical_preds, categorial_labels, numerical_labels, categorial_col_name, numerical_col_name\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_warmup_decay_lr(lr_init, lr_final, num_warmup_steps, num_training_steps):\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return current_step / num_warmup_steps \n",
    "        else:\n",
    "            progress = (current_step - num_warmup_steps) / (num_training_steps - num_warmup_steps)\n",
    "            return (1 - progress) * (1 - lr_final / lr_init) + (lr_final / lr_init)  \n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4\n",
    "EPOCHS = 1 \n",
    "layers_encode = 6\n",
    "layers_decode = 1\n",
    "layers_iterative_transformer = 2\n",
    "num_head = 1\n",
    "dropout = 0.4\n",
    "num_variables = 18\n",
    "cols_name = processed_df_train.columns\n",
    "position_emb_dim = 16\n",
    "feature_emb_size = 16\n",
    "category_var_len = category_var_len\n",
    "\n",
    "is_power_of_two = lambda n: n > 0 and (n & (n - 1)) == 0\n",
    "assert is_power_of_two(position_emb_dim + feature_emb_size), \"position_emb_dim + feature_emb_size should be power term of 2\"\n",
    "\n",
    "model = tableMET(position_emb_dim, layers_encode, layers_decode, layers_iterative_transformer,\\\n",
    "                num_head, num_variables, cols_name, category_vars, feature_emb_size, category_var_len, dropout).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.95), eps=1e-6, weight_decay=1e-3)\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=linear_warmup_decay_lr(lr_init = LEARNING_RATE, lr_final = LEARNING_RATE * 1e-2, num_warmup_steps = 10, num_training_steps = EPOCHS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE_loss_fn = nn.MSELoss()\n",
    "CE_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label):\n",
    "    \n",
    "    num_numerical = 12\n",
    "    num_category = 7\n",
    "    ratio_numerical = num_numerical / (num_numerical + num_category)\n",
    "    ratio_category = 1 / (num_numerical + num_category)\n",
    "    \n",
    "    total_loss = torch.zeros(1).to(device)\n",
    "    \n",
    "    mse_loss = MSE_loss_fn(numerical_pred, numerical_label)\n",
    "    mse_loss = mse_loss * 1 \n",
    "    total_loss += (mse_loss * ratio_numerical)\n",
    "    \n",
    "    for i in range(num_category):\n",
    "        pred = categorial_pred[i]\n",
    "        label = categorial_label[i]        \n",
    "        loss = CE_loss_fn(pred, label.long())\n",
    "        total_loss += (loss * ratio_category)\n",
    "        \n",
    "    return total_loss, mse_loss, (total_loss - mse_loss).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING, total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 0, loss: 2.219996598031786, mse: 2.319740596744749, ce: -0.09974399871296352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterate epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:08<00:00,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALID, total variables are 18: first 12 unmasked, latter 6\n",
      "epoch: 0, val_loss: 2.872875928878784, val_mse: 3.2918390035629272, val_ce_losses: -0.41896307468414307\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tableMET' object has no attribute 'save_pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 78\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_mse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mse_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, val_ce_losses: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ce_losses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28mprint\u001b[39m()      \n\u001b[0;32m---> 78\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoints/FT_MET\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/Vit/lib/python3.12/site-packages/torch/nn/modules/module.py:1928\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1927\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1928\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1930\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tableMET' object has no attribute 'save_pretrained'"
     ]
    }
   ],
   "source": [
    "train_LOSS = []\n",
    "valid_LOSS = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"iterate epoch\"):\n",
    "    \n",
    "    losses = []\n",
    "    mse_losses = []\n",
    "    ce_losses = []\n",
    "    \n",
    "    val_losses = []\n",
    "    val_mse_losses = []\n",
    "    val_ce_losses = []\n",
    "\n",
    "    model.train()\n",
    "    for data, label, mask_ratio in train_dataloader:\n",
    "        unmask_ratio = ((100 - mask_ratio) * num_variables) // 100\n",
    "        \n",
    "        unmasked_data = data[0].float().to(device)\n",
    "        unmasked_idx = data[1].long().to(device)\n",
    "        masked_idx = data[2].long().to(device)\n",
    "        latent = data[3].float().to(device)\n",
    "        label = label.float().to(device)\n",
    "        \n",
    "        categorial_pred, numerical_pred, categorial_label, numerical_label, categorial_col_name,\\\n",
    "            numerical_col_name = model(unmasked_data, unmasked_idx, masked_idx, label, mask_ratio)\n",
    "        \n",
    "        loss, mse_loss, ce_loss = loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label)\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        mse_losses.append(mse_loss.item())\n",
    "        ce_losses.append(ce_loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    losses = np.mean(losses)\n",
    "    mse_losses = np.mean(mse_losses)\n",
    "    ce_losses = np.mean(ce_losses)\n",
    "    train_LOSS.append(losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'TRAINING, total variables are {num_variables}: first {unmask_ratio} unmasked, latter {num_variables - unmask_ratio}')\n",
    "        print(f\"epoch: {epoch}, loss: {losses}, mse: {mse_losses}, ce: {ce_losses}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, label, mask_ratio in valid_dataloader:\n",
    "            unmask_ratio = ((100 - mask_ratio) * num_variables) // 100            \n",
    "            \n",
    "            unmasked_data = data[0].float().to(device)\n",
    "            unmasked_idx = data[1].long().to(device)\n",
    "            masked_idx = data[2].long().to(device)\n",
    "            latent = data[3].float().to(device)\n",
    "            label = label.float().to(device)\n",
    "\n",
    "            categorial_pred, numerical_pred, categorial_label, numerical_label, categorial_col_name,\\\n",
    "                numerical_col_name = model(unmasked_data, unmasked_idx, masked_idx, label, mask_ratio)\n",
    "            \n",
    "            loss, mse_loss, ce_loss = loss_fn(categorial_pred, numerical_pred, categorial_label, numerical_label)\n",
    "\n",
    "            val_losses.append(loss.item())\n",
    "            val_mse_losses.append(mse_loss.item())\n",
    "            val_ce_losses.append(ce_loss)            \n",
    "            \n",
    "    val_losses = np.mean(val_losses)\n",
    "    val_mse_losses = np.mean(val_mse_losses)\n",
    "    val_ce_losses = np.mean(val_ce_losses)\n",
    "    valid_LOSS.append(val_losses)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f'VALID, total variables are {num_variables}: first {unmask_ratio} unmasked, latter {num_variables - unmask_ratio}')\n",
    "        print(f\"epoch: {epoch}, val_loss: {val_losses}, val_mse: {val_mse_losses}, val_ce_losses: {val_ce_losses}\")\n",
    "        print()      \n",
    "\n",
    "model.save_pretrained(\"checkpoints/FT_MET\")\n",
    "  \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_677224/2125145983.py:6: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_LOSS)), train_LOSS, color = 'blue')\n",
    "plt.plot(range(len(valid_LOSS)), valid_LOSS, color = 'red')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_norm(df):\n",
    "    \n",
    "    new_df = pd.DataFrame()\n",
    "    \n",
    "\n",
    "    # Category \n",
    "    for cat_name in category_vars:\n",
    "        cat_var = df[cat_name]\n",
    "        new_df[f'{cat_name}'] = cat_var\n",
    "    \n",
    "    # Numerical score\n",
    "    for num_name in numerical_score_vars:\n",
    "        num_var = df[num_name]\n",
    "        \n",
    "        # reverse (0 - 100) min max norm\n",
    "        num_var = (num_var * 100) + 0\n",
    "        \n",
    "        new_df[num_name] = num_var.values\n",
    "    \n",
    "    # Numerical scalar\n",
    "    for num_name in numerical_scalar_vars:\n",
    "        num_var = df[num_name]\n",
    "        \n",
    "        # reverse (0 - 10) min max norm\n",
    "        num_var = (num_var * 10) + 0\n",
    "        # reverse\n",
    "        num_var = np.exp(num_var)\n",
    "        new_df[num_name] = num_var.values\n",
    "        \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_sample_id = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categorial_pred_one: (7,)\n",
      "categorial_label_one: (7,)\n",
      "numerical_pred_one: (11,)\n",
      "numerical_label_one: (11,)\n"
     ]
    }
   ],
   "source": [
    "unmasked_idx_one = np.array(unmasked_idx[select_sample_id].detach().cpu(), dtype=int)\n",
    "masked_idx_one = np.array(masked_idx[select_sample_id].detach().cpu(), dtype=int)\n",
    "\n",
    "\n",
    "categorial_pred_one = []\n",
    "for pred in categorial_pred:\n",
    "    argmax_pred = torch.argmax(pred, dim = 1)\n",
    "    categorial_pred_one.append(argmax_pred)\n",
    "categorial_pred_one = torch.stack(categorial_pred_one, dim = 1)\n",
    "categorial_pred_one = np.array(categorial_pred_one[select_sample_id].detach().cpu())\n",
    "\n",
    "categorial_label_one = torch.stack(categorial_label, dim = 1)\n",
    "categorial_label_one = np.array(categorial_label_one[select_sample_id].detach().cpu())\n",
    "\n",
    "numerical_pred_one = np.array(numerical_pred[select_sample_id].detach().cpu())\n",
    "numerical_label_one = np.array(numerical_label[select_sample_id].detach().cpu())\n",
    "\n",
    "\n",
    "print(f\"categorial_pred_one: {categorial_pred_one.shape}\")\n",
    "print(f\"categorial_label_one: {categorial_label_one.shape}\")\n",
    "print(f\"numerical_pred_one: {numerical_pred_one.shape}\")\n",
    "print(f\"numerical_label_one: {numerical_label_one.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Grade',\n",
       " 'Internet_Access_at_Home',\n",
       " 'Family_Income_Level',\n",
       " 'Gender',\n",
       " 'Department',\n",
       " 'Extracurricular_Activities',\n",
       " 'Parent_Education_Level']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorial_col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: (18,)\n",
      "label: (18,)\n"
     ]
    }
   ],
   "source": [
    "pred = np.concat([categorial_pred_one, numerical_pred_one], axis = 0)\n",
    "label = np.concat([categorial_label_one, numerical_label_one], axis = 0)\n",
    "\n",
    "print(f\"pred: {pred.shape}\")\n",
    "print(f\"label: {label.shape}\")\n",
    "\n",
    "res = pd.DataFrame([pred, label], columns = categorial_col_name + numerical_col_name)\n",
    "reverse_res = reverse_norm(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Department</th>\n",
       "      <th>Extracurricular_Activities</th>\n",
       "      <th>Parent_Education_Level</th>\n",
       "      <th>Midterm_Score</th>\n",
       "      <th>Total_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-43.065909</td>\n",
       "      <td>-13.123268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.100001</td>\n",
       "      <td>50.220001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Department  Extracurricular_Activities  Parent_Education_Level  \\\n",
       "0     0.0         4.0                         2.0                     3.0   \n",
       "1     0.0         1.0                         1.0                     0.0   \n",
       "\n",
       "   Midterm_Score  Total_Score  \n",
       "0     -43.065909   -13.123268  \n",
       "1      45.100001    50.220001  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_res[cols_name[masked_idx_one]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grade</th>\n",
       "      <th>Internet_Access_at_Home</th>\n",
       "      <th>Family_Income_Level</th>\n",
       "      <th>Attendance (%)</th>\n",
       "      <th>Final_Score</th>\n",
       "      <th>Assignments_Avg</th>\n",
       "      <th>Quizzes_Avg</th>\n",
       "      <th>Projects_Score</th>\n",
       "      <th>Sleep_Hours_per_Night</th>\n",
       "      <th>Study_Hours_per_Week</th>\n",
       "      <th>Age</th>\n",
       "      <th>Stress_Level (1-10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-39.918190</td>\n",
       "      <td>-130.266321</td>\n",
       "      <td>-258.843493</td>\n",
       "      <td>-141.264093</td>\n",
       "      <td>-25.150052</td>\n",
       "      <td>1847.221695</td>\n",
       "      <td>6.233822e-07</td>\n",
       "      <td>3.754792e-09</td>\n",
       "      <td>6.893634e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>80.299997</td>\n",
       "      <td>76.289999</td>\n",
       "      <td>83.420002</td>\n",
       "      <td>65.230000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>2.110000e+01</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grade  Internet_Access_at_Home  Family_Income_Level  Attendance (%)  \\\n",
       "0    2.0                      2.0                  1.0      -39.918190   \n",
       "1    2.0                      1.0                  2.0       80.299997   \n",
       "\n",
       "   Final_Score  Assignments_Avg  Quizzes_Avg  Projects_Score  \\\n",
       "0  -130.266321      -258.843493  -141.264093      -25.150052   \n",
       "1    76.289999        83.420002    65.230000       93.500000   \n",
       "\n",
       "   Sleep_Hours_per_Night  Study_Hours_per_Week           Age  \\\n",
       "0            1847.221695          6.233822e-07  3.754792e-09   \n",
       "1               7.400000          2.110000e+01  2.400000e+01   \n",
       "\n",
       "   Stress_Level (1-10)  \n",
       "0         6.893634e-09  \n",
       "1         5.000000e+00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_res[cols_name[unmasked_idx_one]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sleep_Hours_per_Night', 'Study_Hours_per_Week', 'Age', 'Stress_Level (1-10)']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_vars = ['Gender', 'Department', 'Grade', 'Extracurricular_Activities', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Family_Income_Level']\n",
    "numerical_score_vars = ['Attendance (%)', 'Midterm_Score', 'Final_Score', 'Assignments_Avg', 'Quizzes_Avg', 'Projects_Score', 'Total_Score']\n",
    "numerical_scalar_vars = list(set(filtered_df.columns) - set(category_vars) - set(numerical_score_vars))\n",
    "numerical_scalar_vars\n",
    "# ['Study_Hours_per_Week', 'Age', 'Stress_Level (1-10)', 'Sleep_Hours_per_Night']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
